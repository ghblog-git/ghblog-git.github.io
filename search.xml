<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>数据结构学习笔记之链表</title>
      <link href="/posts/7628/"/>
      <url>/posts/7628/</url>
      
        <content type="html"><![CDATA[<h1><font color="red">给自己定个小目标 待学习·····</font></h1>  ]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
          <category> 链表 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构之连续存储</title>
      <link href="/posts/25393/"/>
      <url>/posts/25393/</url>
      
        <content type="html"><![CDATA[<h2 id="预备知识—指针"><a href="#预备知识—指针" class="headerlink" title="预备知识—指针"></a>预备知识—指针</h2><p>指针：  </p><ul><li>指针就是地址</li><li>指针变量是存放地址的变量</li><li>指针的本质是一个操作受限的非负整数</li></ul><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="线性结构"><a href="#线性结构" class="headerlink" title="线性结构"></a>线性结构</h3><p>把所有节点用一根直线串起来  </p><ul><li>连续存储  【数组】</li><li>离散存储  【链表】</li></ul><p>线性结构常用两种应用： 栈，队列  </p><p>数组与指针</p><p>数组的增删改查：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span><span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Arr</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">int</span> *pBase; <span class="comment">//数组首地址</span></span><br><span class="line">    <span class="keyword">int</span> cnt; <span class="comment">// 数组内有效值个数</span></span><br><span class="line">    <span class="keyword">int</span> len; <span class="comment">// 数组长度</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init_arr</span><span class="params">(struct Arr *arr, <span class="keyword">int</span> length)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_arr</span><span class="params">(struct Arr *parr)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">is_empty</span><span class="params">(struct Arr *parr)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">is_full</span><span class="params">(struct Arr *parr)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">append_arr</span><span class="params">(struct Arr *parr, <span class="keyword">int</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">insert_arr</span><span class="params">(struct Arr *parr, <span class="keyword">int</span> pos, <span class="keyword">int</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reverse_arr</span><span class="params">(struct Arr *parr)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sort_arr</span><span class="params">(struct Arr *parr)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Arr</span> <span class="title">arr</span>;</span></span><br><span class="line"></span><br><span class="line">    init_arr(&amp;arr, <span class="number">6</span>);</span><br><span class="line">    <span class="comment">// show_arr(&amp;arr);</span></span><br><span class="line">    append_arr(&amp;arr, <span class="number">1</span>);</span><br><span class="line">    append_arr(&amp;arr, <span class="number">2</span>);</span><br><span class="line">    insert_arr(&amp;arr, <span class="number">2</span>, <span class="number">9</span>);</span><br><span class="line">    append_arr(&amp;arr, <span class="number">5</span>);</span><br><span class="line">    append_arr(&amp;arr, <span class="number">-1</span>);</span><br><span class="line">    show_arr(&amp;arr);</span><br><span class="line">    reverse_arr(&amp;arr);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"resveer==========\n"</span>);</span><br><span class="line">    show_arr(&amp;arr);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"sort=============\n"</span>);</span><br><span class="line">    sort_arr(&amp;arr);</span><br><span class="line">    show_arr(&amp;arr);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init_arr</span><span class="params">(struct Arr *parr, <span class="keyword">int</span> length)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    parr-&gt;pBase = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">int</span>) * length);</span><br><span class="line">    <span class="keyword">if</span> (parr-&gt;pBase == <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"failed to allocate dynamic memory !\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">-1</span>); <span class="comment">// 终止程序</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        parr-&gt;len = length;</span><br><span class="line">        parr-&gt;cnt = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">"Initialize array successfully\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_arr</span><span class="params">(struct Arr *parr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (is_empty(parr))</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"the array is empty\n"</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; (*parr).cnt; i++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"content of the array: %d\n"</span>, *(parr-&gt;pBase + i));</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">is_empty</span><span class="params">(struct Arr *parr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (parr-&gt;cnt == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">is_full</span><span class="params">(struct Arr *parr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (parr-&gt;cnt == parr-&gt;len)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">append_arr</span><span class="params">(struct Arr *parr, <span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (is_full(parr))</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"the array is  already full !\n"</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        parr-&gt;pBase[parr-&gt;cnt] = val;</span><br><span class="line">        (parr-&gt;cnt)++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">      </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">insert_arr</span><span class="params">(struct Arr *parr, <span class="keyword">int</span> pos, <span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (is_full(parr))</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"the array is already full !\n"</span>);</span><br><span class="line">    <span class="keyword">if</span> (pos &lt;<span class="number">1</span> || pos &gt; (parr-&gt;cnt + <span class="number">1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"failed to insert \n"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = parr-&gt;cnt; i &gt;= pos<span class="number">-1</span>; i--)</span><br><span class="line">            parr-&gt;pBase[i] = parr-&gt;pBase[i<span class="number">-1</span>];      </span><br><span class="line">        parr-&gt;pBase[pos<span class="number">-1</span>] = val;</span><br><span class="line">        (parr-&gt;cnt)++; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reverse_arr</span><span class="params">(struct Arr *parr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> j = parr-&gt;cnt - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> t;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; j)</span><br><span class="line">    &#123;</span><br><span class="line">        t = parr-&gt;pBase[i];</span><br><span class="line">        parr-&gt;pBase[i] = parr-&gt;pBase[j];</span><br><span class="line">        parr-&gt;pBase[j] = t;</span><br><span class="line">        i++;</span><br><span class="line">        j--;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sort_arr</span><span class="params">(struct Arr *parr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, j, t;</span><br><span class="line">    <span class="keyword">for</span> ( i = <span class="number">0</span>; i &lt; parr-&gt;cnt; i++)</span><br><span class="line">    &#123;</span><br><span class="line">       <span class="keyword">for</span> ( j = i+<span class="number">1</span>; j &lt; parr-&gt;cnt; j++)</span><br><span class="line">       &#123;</span><br><span class="line">           <span class="keyword">if</span> (parr-&gt;pBase[i] &gt; parr-&gt;pBase[j])</span><br><span class="line">           &#123;</span><br><span class="line">               t = parr-&gt;pBase[i];</span><br><span class="line">               parr-&gt;pBase[i] = parr-&gt;pBase[j];</span><br><span class="line">               parr-&gt;pBase[j] = t;</span><br><span class="line">           &#125;         </span><br><span class="line">       &#125;    </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>js事件</title>
      <link href="/posts/14994/"/>
      <url>/posts/14994/</url>
      
        <content type="html"><![CDATA[<ul><li>事件源</li><li>事件名</li><li>事件监听</li><li>事件处理</li></ul><h2 id="事件类型"><a href="#事件类型" class="headerlink" title="事件类型"></a>事件类型</h2><p>javascript可以处理的事件类型为: 鼠标事件、键盘事件、HTML事件。  </p><p>几个常用的事件:<br>    <font color="red"> onclick, onblur, onfocus, onload,onchange, onmouseover, onmouseout, onkeyup, onkeydown</font></p><h2 id="事件流和事件模型"><a href="#事件流和事件模型" class="headerlink" title="事件流和事件模型"></a>事件流和事件模型</h2><p>事件流: 接收事件的顺序。<br>事件顺序: 事件捕获(从大到小)和事件冒泡(从小到大)。<br>冒泡和捕获其实都是事件流的不同表现，这两者的产生是因为IE和Netscape两大公司完全不同的事件流概念产生的。（事件流: 是指页面接收事件的顺序）IE的事件流是事件冒泡，Netscaape的事件流是事件捕获流。</p><h2 id="事件处理程序"><a href="#事件处理程序" class="headerlink" title="事件处理程序"></a>事件处理程序</h2><ol><li>HTML事件处理程序</li><li>DOM 0级事件处理程序<ul><li>将一个函数赋值给一个事件处理程序属性  </li></ul></li><li>DOM 级事件处理程序<ul><li>可以为同一个元素同一个事件设定多个事件程序</li></ul></li></ol><p>DOM 0级事件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;button id&#x3D;&quot;btn&quot;&gt;button&lt;&#x2F;button&gt;</span><br><span class="line">var btn &#x3D; document.getElementById(&#39;btn&#39;);</span><br><span class="line">btn.onclick &#x3D; function()&#123;</span><br><span class="line">    console.log(&quot;supervision...&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>DOM 2级事件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;button id&#x3D;&quot;btn2&quot;&gt;button&lt;&#x2F;button&gt;</span><br><span class="line">var btn2 &#x3D; document.getElementById(&#39;btn2&#39;);</span><br><span class="line">btn2.addEventListener(&#39;事件名&#39;, &#39;函数名1&#39;);</span><br><span class="line">btn2.addEventListener(&#39;事件名&#39;, &#39;函数名2&#39;);</span><br><span class="line">btn2.removeEventListener(&#39;事件名&#39;, &#39;函数名2&#39;);</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> js </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>resnet + flask</title>
      <link href="/posts/51850/"/>
      <url>/posts/51850/</url>
      
        <content type="html"><![CDATA[<p>用resnet模型来训练mnist手写数字集是大材小用了，不过作为来学习也说得过去<br>近来学习深度学习每次都是训练完数据，loss降低，accuracy上升之后便保存模型没了后续，<br>最近找到一个项目便是将深度学习模型部署在flask，大大增强趣味性与交互性。  </p><p>原项目地址：<a href="https://github.com/ybsdegit/Keras_flask_mnist" target="_blank" rel="noopener">ybsdegit/Keras_flask_mnist: 基于 Keras + Flask 的 Mnist 手写数字集识别系统 (github.com)</a><br>界面展示<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/ghblog-git/img/images/mnist.png"  alt="">  </p><p>下边是训练过程， 可以看到在测试集上的正确率也高达98%，效果甚佳。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Epoch 2&#x2F;10</span><br><span class="line">469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 200s 426ms&#x2F;step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0494 - val_accuracy: 0.9863</span><br><span class="line">Epoch 3&#x2F;10</span><br><span class="line">469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 204s 434ms&#x2F;step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0567 - val_accuracy: 0.9823</span><br><span class="line">Epoch 4&#x2F;10</span><br><span class="line">469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 204s 435ms&#x2F;step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0994 - val_accuracy: 0.9721</span><br><span class="line">Epoch 5&#x2F;10</span><br><span class="line">469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 204s 434ms&#x2F;step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0414 - val_accuracy: 0.9894</span><br><span class="line">Epoch 6&#x2F;10</span><br><span class="line">469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 204s 435ms&#x2F;step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0907 - val_accuracy: 0.9758</span><br><span class="line">Epoch 7&#x2F;10</span><br><span class="line">469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 204s 435ms&#x2F;step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0489 - val_accuracy: 0.9857</span><br><span class="line">Epoch 8&#x2F;10</span><br><span class="line">469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 204s 435ms&#x2F;step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0446 - val_accuracy: 0.9888</span><br></pre></td></tr></table></figure><p>resnet.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BasicBlock(tf.keras.layers.Layer):</span><br><span class="line"></span><br><span class="line">    def __init__(self, filter_num, strides&#x3D;1):</span><br><span class="line">        super(BasicBlock, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 &#x3D; tf.keras.layers.Conv2D(filters&#x3D;filter_num, kernel_size&#x3D;(3, 3), strides&#x3D;strides, padding&#x3D;&#39;same&#39;)</span><br><span class="line">        self.bn1 &#x3D; tf.keras.layers.BatchNormalization()</span><br><span class="line">        self.relu &#x3D; tf.keras.layers.Activation(&#39;relu&#39;)</span><br><span class="line"></span><br><span class="line">        self.conv2 &#x3D; tf.keras.layers.Conv2D(filters&#x3D;filter_num, kernel_size&#x3D;(3, 3), strides&#x3D;1, padding&#x3D;&#39;same&#39;)</span><br><span class="line">        self.bn2 &#x3D; tf.keras.layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">        if strides !&#x3D; 1:</span><br><span class="line">            self.downsample &#x3D; tf.keras.Sequential()</span><br><span class="line">            self.downsample.add(tf.keras.layers.Conv2D(filters&#x3D;filter_num, kernel_size&#x3D;(1, 1), strides&#x3D;strides))</span><br><span class="line">        else:</span><br><span class="line">            self.downsample &#x3D; lambda x: x</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training&#x3D;None):</span><br><span class="line"></span><br><span class="line">        out &#x3D; self.conv1(inputs)</span><br><span class="line">        out &#x3D; self.bn1(out)</span><br><span class="line">        out &#x3D; self.relu(out)</span><br><span class="line"></span><br><span class="line">        out &#x3D; self.conv2(out)</span><br><span class="line">        out &#x3D; self.bn2(out)</span><br><span class="line"></span><br><span class="line">        identity &#x3D; self.downsample(inputs)</span><br><span class="line"></span><br><span class="line">        output &#x3D; tf.keras.layers.add([out, identity])</span><br><span class="line">        output &#x3D; tf.nn.relu(output)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ResNet(tf.keras.Model):</span><br><span class="line"></span><br><span class="line">    def __init__(self, layer_dims, num_classes&#x3D;10):</span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.stem &#x3D; tf.keras.Sequential([tf.keras.layers.Conv2D(filters&#x3D;64, kernel_size&#x3D;(3, 3), strides&#x3D;(1, 1)),</span><br><span class="line">                                         tf.keras.layers.BatchNormalization(),</span><br><span class="line">                                         tf.keras.layers.Activation(&#39;relu&#39;),</span><br><span class="line">                                         tf.keras.layers.MaxPool2D(pool_size&#x3D;(2, 2), strides&#x3D;(1, 1), padding&#x3D;&#39;same&#39;)])</span><br><span class="line"></span><br><span class="line">        self.layer1 &#x3D; self.build_resblock(filter_num&#x3D;64,  blocks&#x3D;layer_dims[0])</span><br><span class="line">        self.layer2 &#x3D; self.build_resblock(filter_num&#x3D;128, blocks&#x3D;layer_dims[1], strides&#x3D;2)</span><br><span class="line">        self.layer3 &#x3D; self.build_resblock(filter_num&#x3D;256, blocks&#x3D;layer_dims[2], strides&#x3D;2)</span><br><span class="line">        self.layer4 &#x3D; self.build_resblock(filter_num&#x3D;512, blocks&#x3D;layer_dims[3], strides&#x3D;2)</span><br><span class="line"></span><br><span class="line">        # output:[b, 512, h, w]</span><br><span class="line">        self.avgpool &#x3D; tf.keras.layers.GlobalAveragePooling2D()</span><br><span class="line">        self.fully_con &#x3D; tf.keras.layers.Dense(num_classes)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training&#x3D;None, mask&#x3D;None):</span><br><span class="line"></span><br><span class="line">        x &#x3D; self.stem(inputs)</span><br><span class="line"></span><br><span class="line">        x &#x3D; self.layer1(x)</span><br><span class="line">        x &#x3D; self.layer2(x)</span><br><span class="line">        x &#x3D; self.layer3(x)</span><br><span class="line">        x &#x3D; self.layer4(x)</span><br><span class="line"></span><br><span class="line">        # [b, c]</span><br><span class="line">        x &#x3D; self.avgpool(x)</span><br><span class="line">        # [b, 100]</span><br><span class="line">        x &#x3D; self.fully_con(x)</span><br><span class="line"></span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def build_resblock(self, filter_num, blocks, strides&#x3D;1):</span><br><span class="line"></span><br><span class="line">        res_blocks &#x3D; tf.keras.Sequential()</span><br><span class="line">        res_blocks.add(BasicBlock(filter_num, strides))</span><br><span class="line"></span><br><span class="line">        for _ in range(1, blocks):</span><br><span class="line">            res_blocks.add(BasicBlock(filter_num, strides&#x3D;1))</span><br><span class="line"></span><br><span class="line">        return res_blocks</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def resnet18():</span><br><span class="line"></span><br><span class="line">    return ResNet(layer_dims&#x3D;[2, 2, 2, 2])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def resnet34():</span><br><span class="line"></span><br><span class="line">    return ResNet(layer_dims&#x3D;[3, 4, 6, 3])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># model &#x3D; resnet34()</span><br><span class="line"># model.build(input_shape&#x3D;(None, 32, 32, 3))</span><br><span class="line"># model.summary()</span><br><span class="line">#</span><br><span class="line"># model2 &#x3D; resnet18()</span><br><span class="line"># model2.build(input_shape&#x3D;(None, 32, 32, 3))</span><br><span class="line"># model2.summary()</span><br></pre></td></tr></table></figure></p><p>train.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from RESNET import resnet18</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x &#x3D; tf.cast(x, dtype&#x3D;tf.float32) &#x2F; 255</span><br><span class="line">    y &#x3D; tf.cast(y, dtype&#x3D;tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) &#x3D; tf.keras.datasets.mnist.load_data()</span><br><span class="line">x_train &#x3D; np.expand_dims(x_train, axis&#x3D;3)</span><br><span class="line">x_test &#x3D; np.expand_dims(x_test, axis&#x3D;3)</span><br><span class="line">y_train &#x3D; tf.one_hot(y_train, depth&#x3D;10)</span><br><span class="line">y_test &#x3D; tf.one_hot(y_test, depth&#x3D;10)</span><br><span class="line">db_train &#x3D; tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train &#x3D; db_train.map(preprocess).shuffle(10000).batch(128)</span><br><span class="line">db_test &#x3D; tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test &#x3D; db_test.map(preprocess).batch(128)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># sample &#x3D; next(iter(db_train))</span><br><span class="line"># print(sample[0].shape, sample[1].shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line"></span><br><span class="line">    model &#x3D; resnet18()</span><br><span class="line">    model.build(input_shape&#x3D;(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer&#x3D;tf.optimizers.Adam(lr&#x3D;1e-4),</span><br><span class="line">                  loss&#x3D;tf.losses.CategoricalCrossentropy(from_logits&#x3D;True),</span><br><span class="line">                  metrics&#x3D;[&#39;accuracy&#39;])</span><br><span class="line"></span><br><span class="line">    model.fit(db_train, epochs&#x3D;10, validation_data&#x3D;db_test, validation_freq&#x3D;1)</span><br><span class="line">    model.save(&quot;my_model&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p><p>app.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">import base64</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from flask import Flask, render_template, request</span><br><span class="line">from tensorflow.keras.preprocessing.image import img_to_array, load_img</span><br><span class="line"></span><br><span class="line">app &#x3D; Flask(__name__)</span><br><span class="line"></span><br><span class="line">model_file &#x3D; &#39;.&#x2F;model&#x2F;my_model&#39;</span><br><span class="line">global model</span><br><span class="line"></span><br><span class="line">model &#x3D; tf.keras.models.load_model(model_file)</span><br><span class="line"></span><br><span class="line">@app.route(&#39;&#x2F;&#39;)</span><br><span class="line">def index():</span><br><span class="line">    return render_template(&quot;index.html&quot;) </span><br><span class="line"></span><br><span class="line">@app.route(&#39;&#x2F;predict&#x2F;&#39;, methods&#x3D;[&#39;Get&#39;, &#39;POST&#39;])</span><br><span class="line">def predict():</span><br><span class="line"></span><br><span class="line">    Parse_Image(request.get_data())</span><br><span class="line">    img &#x3D; img_to_array(load_img(&#39;output.png&#39;, target_size&#x3D;(28, 28), color_mode&#x3D;&quot;grayscale&quot;)) &#x2F; 255.</span><br><span class="line">    img &#x3D; np.expand_dims(img, axis&#x3D;0)</span><br><span class="line">    # code &#x3D; model.predict_classes(img)[0]  使用resnet模型时无法用这个方法</span><br><span class="line">    code &#x3D; model.predict(img)</span><br><span class="line">    code &#x3D; np.argmax(code)</span><br><span class="line">    return str(code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def Parse_Image(imgData):</span><br><span class="line"></span><br><span class="line">    imgStr &#x3D; re.search(b&#39;base64,(.*)&#39;, imgData).group(1)</span><br><span class="line">    with open(&#39;.&#x2F;output.png&#39;, &#39;wb&#39;) as output:</span><br><span class="line">        output.write(base64.decodebytes(imgStr))</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    app.run(host&#x3D;&quot;127.0.0.1&quot;, port&#x3D;3335)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> tensorflow </tag>
            
            <tag> flask </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前向传播</title>
      <link href="/posts/39625/"/>
      <url>/posts/39625/</url>
      
        <content type="html"><![CDATA[<h2 id="tensorflow基本操作"><a href="#tensorflow基本操作" class="headerlink" title="tensorflow基本操作"></a>tensorflow基本操作</h2><h3 id="创建tensor"><a href="#创建tensor" class="headerlink" title="创建tensor"></a>创建tensor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tf.convert_to_tensor(np.ones([<span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line">tf.convert_to_tensor(np.zeros([<span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line">tf.convert_to_tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">tf.convert_to_tensor([[<span class="number">1</span>], [<span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">tf.ones([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">tf.ones([<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line">tf.ones([<span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line">tf.ones([<span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">tf.fill([<span class="number">2</span>, <span class="number">3</span>], <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">tf.random.normal([<span class="number">2</span>, <span class="number">2</span>], mean=<span class="number">1</span>, stddev=<span class="number">1</span>)  <span class="comment"># 正态分布</span></span><br><span class="line">tf.random.uniform([<span class="number">2</span>, <span class="number">2</span>], minval=<span class="number">0</span>, maxval=<span class="number">1</span>)  <span class="comment"># 均匀分布</span></span><br><span class="line"></span><br><span class="line">tf.ones([<span class="number">2</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><h3 id="前向传播实战"><a href="#前向传播实战" class="headerlink" title="前向传播实战"></a>前向传播实战</h3><h4 id="step1-导入模块"><a href="#step1-导入模块" class="headerlink" title="step1 导入模块"></a>step1 导入模块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br></pre></td></tr></table></figure><h4 id="step2-导入数据集"><a href="#step2-导入数据集" class="headerlink" title="step2 导入数据集"></a>step2 导入数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), _ = datasets.mnist.load_data()</span><br></pre></td></tr></table></figure><h4 id="step3-处理数据集"><a href="#step3-处理数据集" class="headerlink" title="step3 处理数据集"></a>step3 处理数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_train = tf.convert_to_tensor(x_train, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)</span><br><span class="line"><span class="comment"># print(tf.reduce_max(x_train))</span></span><br><span class="line"></span><br><span class="line">train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(<span class="number">128</span>)</span><br><span class="line">train_iter = iter(train_db)</span><br><span class="line">sample = next(train_iter)</span><br></pre></td></tr></table></figure><h4 id="step4-设置参数"><a href="#step4-设置参数" class="headerlink" title="step4 设置参数"></a>step4 设置参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [b, 784] -&gt; [784, 256] -&gt; [256, 10]</span></span><br><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros(<span class="number">256</span>))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros(<span class="number">128</span>))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros(<span class="number">10</span>))</span><br></pre></td></tr></table></figure><h4 id="step5训练模型"><a href="#step5训练模型" class="headerlink" title="step5训练模型"></a>step5训练模型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">for epoch in range(10):  # iterate dataset</span><br><span class="line">    for step, (x_train, y_train) in enumerate(train_db):    # for every batch  # x.shape: [128, 28, 28] y.shape[128]</span><br><span class="line">        x_train &#x3D; tf.reshape(x_train, [-1, 28*28])  # x.shape: [b, 784]</span><br><span class="line">        with tf.GradientTape() as tape:</span><br><span class="line">            h1 &#x3D; x_train @ w1 + b1  # h1.shape: [b, 256]</span><br><span class="line">            h1 &#x3D; tf.nn.relu(h1)</span><br><span class="line">            h2 &#x3D; h1 @ w2 + b2  # h2.shape: [b, 128]</span><br><span class="line">            h2 &#x3D; tf.nn.relu(h2)</span><br><span class="line">            out &#x3D; h2 @ w3 + b3  # out.shape: [b, 10]</span><br><span class="line"></span><br><span class="line">            # compute loss</span><br><span class="line">            y_hot &#x3D; tf.one_hot(y_train, depth&#x3D;10)</span><br><span class="line">            loss &#x3D; tf.square(y_hot - out)</span><br><span class="line">            loss &#x3D; tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line">        # compute gradients</span><br><span class="line">        grads &#x3D; tape.gradient(loss, [w1, b1, w2, b2, w3, b3])</span><br><span class="line">        # update gradients</span><br><span class="line">        w1.assign_sub(lr * grads[0])</span><br><span class="line">        b1.assign_sub(lr * grads[1])</span><br><span class="line">        w2.assign_sub(lr * grads[2])</span><br><span class="line">        b2.assign_sub(lr * grads[3])</span><br><span class="line">        w3.assign_sub(lr * grads[4])</span><br><span class="line">        b3.assign_sub(lr * grads[5])</span><br><span class="line"></span><br><span class="line">        # w1 &#x3D; tf.Variable(w1 - lr * grads[0])</span><br><span class="line">        # b1 &#x3D; tf.Variable(b1 - lr * grads[1])</span><br><span class="line">        # w2 &#x3D; tf.Variable(w2 - lr * grads[2])</span><br><span class="line">        # b2 &#x3D; tf.Variable(b2 - lr * grads[3])</span><br><span class="line">        # w3 &#x3D; tf.Variable(w3 - lr * grads[4])</span><br><span class="line">        # b3 &#x3D; tf.Variable(b3 - lr * grads[5])</span><br><span class="line"></span><br><span class="line">        if step % 100 &#x3D;&#x3D; 0:</span><br><span class="line">            print(&#39;epoch:&#39;, epoch, &#39;step:&#39;, step, &#39;current loss:&#39;, float(loss))</span><br></pre></td></tr></table></figure><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">(x_train, y_train), _ = datasets.mnist.load_data()</span><br><span class="line">x_train = tf.convert_to_tensor(x_train, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)</span><br><span class="line"><span class="comment"># print(tf.reduce_max(x_train))</span></span><br><span class="line"></span><br><span class="line">train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(<span class="number">128</span>)</span><br><span class="line">train_iter = iter(train_db)</span><br><span class="line">sample = next(train_iter)</span><br><span class="line"><span class="comment"># print('batch:', sample[0].shape, sample[1].shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># [b, 784] -&gt; [784, 256] -&gt; [256, 10]</span></span><br><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros(<span class="number">256</span>))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros(<span class="number">128</span>))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):  <span class="comment"># iterate dataset</span></span><br><span class="line">    <span class="keyword">for</span> step, (x_train, y_train) <span class="keyword">in</span> enumerate(train_db):    <span class="comment"># for every batch  # x.shape: [128, 28, 28] y.shape[128]</span></span><br><span class="line">        x_train = tf.reshape(x_train, [<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>])  <span class="comment"># x.shape: [b, 784]</span></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            h1 = x_train @ w1 + b1  <span class="comment"># h1.shape: [b, 256]</span></span><br><span class="line">            h1 = tf.nn.relu(h1)</span><br><span class="line">            h2 = h1 @ w2 + b2  <span class="comment"># h2.shape: [b, 128]</span></span><br><span class="line">            h2 = tf.nn.relu(h2)</span><br><span class="line">            out = h2 @ w3 + b3  <span class="comment"># out.shape: [b, 10]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute loss</span></span><br><span class="line">            y_hot = tf.one_hot(y_train, depth=<span class="number">10</span>)</span><br><span class="line">            loss = tf.square(y_hot - out)</span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute gradients</span></span><br><span class="line">        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])</span><br><span class="line">        <span class="comment"># update gradients</span></span><br><span class="line">        w1.assign_sub(lr * grads[<span class="number">0</span>])</span><br><span class="line">        b1.assign_sub(lr * grads[<span class="number">1</span>])</span><br><span class="line">        w2.assign_sub(lr * grads[<span class="number">2</span>])</span><br><span class="line">        b2.assign_sub(lr * grads[<span class="number">3</span>])</span><br><span class="line">        w3.assign_sub(lr * grads[<span class="number">4</span>])</span><br><span class="line">        b3.assign_sub(lr * grads[<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># w1 = tf.Variable(w1 - lr * grads[0])</span></span><br><span class="line">        <span class="comment"># b1 = tf.Variable(b1 - lr * grads[1])</span></span><br><span class="line">        <span class="comment"># w2 = tf.Variable(w2 - lr * grads[2])</span></span><br><span class="line">        <span class="comment"># b2 = tf.Variable(b2 - lr * grads[3])</span></span><br><span class="line">        <span class="comment"># w3 = tf.Variable(w3 - lr * grads[4])</span></span><br><span class="line">        <span class="comment"># b3 = tf.Variable(b3 - lr * grads[5])</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'epoch:'</span>, epoch, <span class="string">'step:'</span>, step, <span class="string">'current loss:'</span>, float(loss))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电路笔记---第一章</title>
      <link href="/posts/2462/"/>
      <url>/posts/2462/</url>
      
        <content type="html"><![CDATA[<h2 id="第一章-电路模型和电路定律"><a href="#第一章-电路模型和电路定律" class="headerlink" title="第一章  电路模型和电路定律"></a>第一章  电路模型和电路定律</h2><h3 id="1-电路和电路模型"><a href="#1-电路和电路模型" class="headerlink" title="1. 电路和电路模型"></a>1. 电路和电路模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">五种基本的理想电路元件：</span><br><span class="line"></span><br><span class="line">​电阻元件：表示消耗电能的元件</span><br><span class="line"></span><br><span class="line">​电感元件：表示产生磁场，储存磁场能量的元件</span><br><span class="line"></span><br><span class="line">​电容元件：表示产生电场，存储电场能量的元件</span><br><span class="line"></span><br><span class="line">​电压源和电流源：表示将其它形式的能量转变成电能的元件</span><br><span class="line"></span><br><span class="line">理想元件的特征：</span><br><span class="line"></span><br><span class="line">1. 只有两个端子</span><br><span class="line">2. 可以用电压或电流按数学方式描述</span><br><span class="line">3. 不能被分解为其它元件</span><br></pre></td></tr></table></figure><p>​    </p><h3 id="2-电流和电压的参考方向"><a href="#2-电流和电压的参考方向" class="headerlink" title="2. 电流和电压的参考方向"></a>2. 电流和电压的参考方向</h3><p>电流：带电粒子有规则的定向运动</p><p>电流强度：单位时间内通过导体横截面的电荷量</p><script type="math/tex; mode=display">i(t) = \lim_{\Delta x \to 0} \frac{\Delta q}{\Delta t} =\frac{dq}{dt}</script><h3 id="3-电功率和能量"><a href="#3-电功率和能量" class="headerlink" title="3. 电功率和能量"></a>3. 电功率和能量</h3><h3 id="4-电路元件"><a href="#4-电路元件" class="headerlink" title="4. 电路元件"></a>4. 电路元件</h3><h3 id="5-电阻元件"><a href="#5-电阻元件" class="headerlink" title="5. 电阻元件"></a>5. 电阻元件</h3><h3 id="6-电压源和电流源"><a href="#6-电压源和电流源" class="headerlink" title="6. 电压源和电流源"></a>6. 电压源和电流源</h3><h3 id="7-受控电源"><a href="#7-受控电源" class="headerlink" title="7.  受控电源"></a>7.  受控电源</h3><h3 id="8-基尔霍夫定律"><a href="#8-基尔霍夫定律" class="headerlink" title="8. 基尔霍夫定律"></a>8. 基尔霍夫定律</h3>]]></content>
      
      
      <categories>
          
          <category> 电路 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习入门（四）</title>
      <link href="/posts/51320/"/>
      <url>/posts/51320/</url>
      
        <content type="html"><![CDATA[<h2 id="猫狗数据集预处理"><a href="#猫狗数据集预处理" class="headerlink" title="猫狗数据集预处理"></a>猫狗数据集预处理</h2><h3 id="文件处理"><a href="#文件处理" class="headerlink" title="文件处理"></a>文件处理</h3><ol><li>首先创建指定目录结构  </li></ol><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/ghblog-git/img/images/model05.png"  alt="">  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creat_dir</span><span class="params">(path)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                os.makedirs(path)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                print(<span class="string">'Create a failure'</span>)</span><br><span class="line"></span><br><span class="line">path = <span class="string">'E:/datasets'</span> </span><br><span class="line"></span><br><span class="line">creat_dir(path + <span class="string">"train/dogs"</span>)</span><br><span class="line">creat_dir(path + <span class="string">"train/cats"</span>)</span><br><span class="line">creat_dir(path + <span class="string">"test/dogs"</span>)</span><br><span class="line">creat_dir(path + <span class="string">"test/cats"</span>)</span><br></pre></td></tr></table></figure><ol><li>将训练所需图片放到指定文件夹  </li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">base_path = <span class="string">'E:\jupyter\dataset\cat_dog\train'</span></span><br><span class="line"></span><br><span class="line">dogs=[os.path.join(base_path, i) <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(train) <span class="keyword">if</span> <span class="string">'dog'</span> <span class="keyword">in</span> i]</span><br><span class="line">cats=[os.path.join(base_path, i) <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(train) <span class="keyword">if</span> <span class="string">'cat'</span> <span class="keyword">in</span> i]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> dog,cat <span class="keyword">in</span> list(zip(dogs,cats))[:<span class="number">1000</span>]:</span><br><span class="line">    new_path_dog = path + <span class="string">"train/dogs/"</span> + os.path.basename(dog)</span><br><span class="line">    shutil.copyfile(dog, new_path_dog)</span><br><span class="line">    print(os.path.basename(dog) + <span class="string">" operate successfully"</span>)</span><br><span class="line"></span><br><span class="line">    new_path_cat = path + <span class="string">"train/cats/"</span> + os.path.basename(cat)</span><br><span class="line">    shutil.copyfile(cat, new_path_cat)</span><br><span class="line">    print(os.path.basename(cat) + <span class="string">"operate successfully"</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> dog, cat <span class="keyword">in</span> list(zip(dogs, cats))[<span class="number">1000</span>:<span class="number">1500</span>]:</span><br><span class="line">    new_path_dog = path + <span class="string">"test/dogs/"</span> + os.path.basename(dog)</span><br><span class="line">    shutil.copyfile(dog, new_path_dog)</span><br><span class="line">    print(os.path.basename(dog) + <span class="string">" operate successfully"</span>)</span><br><span class="line"></span><br><span class="line">    new_path_cat = path + <span class="string">"test/cats/"</span> + os.path.basename(cat)</span><br><span class="line">    shutil.copyfile(cat, new_path_cat)</span><br><span class="line">    print(os.path.basename(cat) + <span class="string">"operate successfully"</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> CNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习入门（三）</title>
      <link href="/posts/42681/"/>
      <url>/posts/42681/</url>
      
        <content type="html"><![CDATA[<h2 id="卷积神经网络介绍"><a href="#卷积神经网络介绍" class="headerlink" title="卷积神经网络介绍"></a>卷积神经网络介绍</h2><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><blockquote><p>三个参数  </p></blockquote><ol><li>ksize<ul><li>卷积核的大小 （n*n的卷积核采样）</li></ul></li><li>strides<ul><li>卷积核移动的跨度  （每次采样的步长）</li></ul></li><li>padding<ul><li>边缘填充  （使采样均匀）</li></ul></li></ol><h3 id="非线性变换层"><a href="#非线性变换层" class="headerlink" title="非线性变换层"></a>非线性变换层</h3><p>激活函数</p><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>使图像像素变小</p><ol><li>最大池化</li><li>平均池化</li></ol><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>w*x + b </p><h2 id="卷积神经网络玩转mnist数据集"><a href="#卷积神经网络玩转mnist数据集" class="headerlink" title="卷积神经网络玩转mnist数据集"></a>卷积神经网络玩转mnist数据集</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train.shape, y_train.shape</span><br><span class="line">((60000, 28, 28), (60000,))</span><br></pre></td></tr></table></figure><p>keras要求输入的dataformate.(batch, height, weight, channel)<br>mnist数据集缺少channel这一维度，因此需要扩充维度，我们使用numpy的一个方法：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train &#x3D; np.expand_dims(x_train, axis&#x3D;-1)</span><br><span class="line">x_test &#x3D; np.expand_dims(x_test, axis&#x3D;-1)</span><br><span class="line">x_train.shape, x_test.shape</span><br><span class="line">((60000, 28, 28, 1), (10000, 28, 28, 1))</span><br></pre></td></tr></table></figure><p>可以看到现在完全符合keras的dataformate标准  </p><h3 id="搭建模型"><a href="#搭建模型" class="headerlink" title="搭建模型"></a>搭建模型</h3><p>根据卷积神经网络的结构：  </p><ol><li>卷积</li><li>池化</li><li>卷积</li><li>池化</li><li>全连接</li></ol><p>卷积 + 池化  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; keras.Sequential()</span><br><span class="line">model.add(layers.Conv2D(64, (3,3), activation&#x3D;&#39;relu&#39;, input_shape&#x3D;(28,28,1)))</span><br><span class="line">model.add(layers.Conv2D(64, (3,3), activation&#x3D;&#39;relu&#39;))</span><br><span class="line">model.add(layers.MaxPooling2D())</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>全连接  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(256, activation&#x3D;&#39;relu&#39;))</span><br><span class="line">model.add(layers.Dropout(0.5))</span><br><span class="line">model.add(layers.Dense(10, activation&#x3D;&#39;softmax&#39;))</span><br></pre></td></tr></table></figure><p>model.summary  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential_2&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_2 (Conv2D)            (None, 24, 24, 64)        36928     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten_1 (Flatten)          (None, 9216)              0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 256)               2359552   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_1 (Dropout)          (None, 256)               0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (None, 10)                2570      </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 2,399,690</span><br><span class="line">Trainable params: 2,399,690</span><br><span class="line">Non-trainable params: 0</span><br></pre></td></tr></table></figure><h3 id="编译，训练模型"><a href="#编译，训练模型" class="headerlink" title="编译，训练模型"></a>编译，训练模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer&#x3D;&#39;adam&#39;,</span><br><span class="line">            loss&#x3D;&#39;sparse_categorical_crossentropy&#39;,</span><br><span class="line">             metrics&#x3D;[&#39;accuracy&#39;])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, epochs&#x3D;10, batch_size&#x3D;512)</span><br></pre></td></tr></table></figure><p>训练集测试结果  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Epoch 9&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 121s 2ms&#x2F;step - loss: 0.0265 - accuracy: 0.9911</span><br><span class="line">Epoch 10&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 130s 2ms&#x2F;step - loss: 0.0267 - accuracy: 0.9912</span><br></pre></td></tr></table></figure><p>可以看到正确率轻松达到99%，看一下在测试集的表现吧  </p><p>测试集测试结果  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(x_test, y_test)</span><br><span class="line">[0.04169193260611291, 0.9886999726295471]</span><br></pre></td></tr></table></figure><p>由此可见，卷积神经网络非常适合图像识别。</p>]]></content>
      
      
      <categories>
          
          <category> CNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>test</title>
      <link href="/posts/52268/"/>
      <url>/posts/52268/</url>
      
        <content type="html"><![CDATA[<h2 id="test"><a href="#test" class="headerlink" title="test"></a>test</h2><font color="red">公式一</font> $$ f'(ζ)=\frac{f(b)-f(a)}{b-a} \\r(A^*)=\begin{cases}n & r(A) = n, \\1 & r(A) = n-1, \\  0 & r(A) < n-1,\end{cases}$$  由此公式$$f'(ζ)=\frac{f(b)-f(a)}{b-a}$$得：  $$ f'(ζ)=\frac{f(b)-f(a)}{b-a} $$<font style="font-size: 100px">❤</font> <p>:smile:<br>:dog:  </p><h2 id="😀"><a href="#😀" class="headerlink" title="😀"></a>😀</h2><h2 id="😈"><a href="#😈" class="headerlink" title="😈"></a>😈</h2><p>test测试<font style="font-size: 20px">🐸</font> </p><h1 id="❤"><a href="#❤" class="headerlink" title="❤"></a>❤</h1><p><i class="fa fa-weixin fa-2x fa-spin" style="color: green"></i><a href="">test</a>  </p><p><i class="fa fa-weibo fa-2x fa-spin" style="color: red"></i><a href="">test</a>  </p><p><i class="fa  fa-battery-full fa-2x fa-pulse" style="color: pink"></i><a href="">test</a>  </p><p><script defer src="https://use.fontawesome.com/releases/v5.0.13/js/all.js"></script> </p><p><script defer src="https://use.fontawesome.com/releases/v5.0.13/js/v4-shims.js"></script> </p><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css">]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习入门（二）</title>
      <link href="/posts/43712/"/>
      <url>/posts/43712/</url>
      
        <content type="html"><![CDATA[<blockquote><p>MNIST数据集是一个手写体数据集，由四部分组成，训练图片集，训练标签集，测试图片集，测试标签集；这个其实并不是普通的文本文件或是图片文件，而是一个压缩文件。<br>MNIST数据集在深度学习中的地位就好像helloword在学习编程时的地位，所以下边开始对这个数据集的学习。</p></blockquote><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><p>keras内置了mnist数据集，我们可以直接调用方法去下载  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = data.load_data()</span><br></pre></td></tr></table></figure><p>这样keras就会自动的去官网下载数据集了，但是这样的下载速度太慢了，一般下载到一般会失败，所以我们直接手动下载下来然后本地读取，这里的读取有两种方法：</p><ol><li><p>到这个文件夹下把下载好的数据集放进去 “C:\Users\your username.keras\datasets” </p><ul><li>推荐使用这种方法，这样可以直接调用keras内置方法data.load_data()去读取</li></ul></li><li><p>将下载好的数据集放在任意位置，然后根据源代码，自己写个函数去读取：</p><ul><li>不推荐<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">()</span>:</span></span><br><span class="line">    path = <span class="string">r'E:\dataset\mnist.npz'</span> </span><br><span class="line">    f = np.load(path)</span><br><span class="line">    x_train, y_train = f[<span class="string">'x_train'</span>], f[<span class="string">'y_train'</span>]</span><br><span class="line">    x_test, y_test = f[<span class="string">'x_test'</span>], f[<span class="string">'y_test'</span>]</span><br><span class="line">    f.close()</span><br><span class="line">    <span class="keyword">return</span> (x_train, y_train), (x_test, y_test)</span><br></pre></td></tr></table></figure></li></ul></li></ol><p>我们可以看到训练集有60000张图片，像素为28<em>28<br>测试集有10000张图片，像素为28</em>28<br>我们取出数据集中某张图片，可以看到他的图片和标签。   </p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/ghblog-git/img/images/model04.png"  alt=""></p><h2 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(layers.Flatten())  <span class="comment"># 将mnist数据集中的(60000, 28, 28) ---&gt; (60000, 28*28, 1)</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))   <span class="comment"># 将28*28全连接到64个单元</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))  <span class="comment"># 将64全连接到10个单元</span></span><br></pre></td></tr></table></figure><h2 id="编译模型"><a href="#编译模型" class="headerlink" title="编译模型"></a>编译模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">            optimizer=<span class="string">'adam'</span>,</span><br><span class="line">            loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train, y_train, epochs&#x3D;50, batch_size&#x3D;512)  # batch_size一次训练所取样本数</span><br><span class="line"></span><br><span class="line">Epoch 47&#x2F;50</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 12us&#x2F;step - loss: 0.0676 - accuracy: 0.9818</span><br><span class="line">Epoch 48&#x2F;50</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 12us&#x2F;step - loss: 0.0570 - accuracy: 0.9833</span><br><span class="line">Epoch 49&#x2F;50</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 13us&#x2F;step - loss: 0.0538 - accuracy: 0.9843</span><br><span class="line">Epoch 50&#x2F;50</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 11us&#x2F;step - loss: 0.0517 - accuracy: 0.9851</span><br></pre></td></tr></table></figure><h2 id="抑制过拟合"><a href="#抑制过拟合" class="headerlink" title="抑制过拟合"></a>抑制过拟合</h2><p>可以看到训练后的模型在训练集上精确度很高，但是我们在测试集上测试他的精确度就偏低了，这就是发生了过拟合现象，某个神经元所占的权重过大了，为了抑制这种现象的发生，我们采用Dropout的方法，随机掐死一些神经元，防止出现一家独大的现象。</p><p>随机掐死一般的神经元<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(layers.Flatten())  <span class="comment"># 将mnist数据集中的(60000, 28, 28) ---&gt; (60000, 28*28, 1)</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))   <span class="comment"># 将28*28全连接到64个单元</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)) </span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)) </span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))  <span class="comment"># 将64全连接到10个单元</span></span><br></pre></td></tr></table></figure></p><p>现在可以明显看到模型在训练集和测试集上准确率很接近，成功抑制了过拟合现象。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch 48&#x2F;50</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 13us&#x2F;step - loss: 0.1782 - accuracy: 0.9536 - val_loss: 0.2408 - val_accuracy: 0.9426</span><br><span class="line">Epoch 49&#x2F;50</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 13us&#x2F;step - loss: 0.1695 - accuracy: 0.9546 - val_loss: 0.2471 - val_accuracy: 0.9448</span><br><span class="line">Epoch 50&#x2F;50</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 13us&#x2F;step - loss: 0.1690 - accuracy: 0.9556 - val_loss: 0.2412 - val_accuracy: 0.9442</span><br></pre></td></tr></table></figure></p><h2 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(x_test, y_test)  </span><br><span class="line"></span><br><span class="line">10000&#x2F;10000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 18us&#x2F;step</span><br><span class="line">[0.24123203506022692, 0.9441999793052673]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> keras </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机视觉</title>
      <link href="/posts/62963/"/>
      <url>/posts/62963/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Day01   </p></blockquote><h2 id="Nearest-Neighbor"><a href="#Nearest-Neighbor" class="headerlink" title="Nearest Neighbor"></a>Nearest Neighbor</h2><p>Memorize all data and labels  </p><p>Predict the label of the most similar training image </p><p>The nearest neighbor algorithm is the lazy algorithm</p><h2 id="K-Nearest-Neighbors"><a href="#K-Nearest-Neighbors" class="headerlink" title="K-Nearest Neighbors"></a>K-Nearest Neighbors</h2><p>instead of copying label from nearest neighbors, take majority vote from K closest points.  </p><p>K-Nearest Neighbors on images never used  </p><ul><li>Very slow at test time  </li><li>Distance metrices on pixels are not informative </li></ul><p>Distance metrices and K are hyperparameters  </p><blockquote><p>Day02  </p></blockquote><h2 id="Linear-Classification"><a href="#Linear-Classification" class="headerlink" title="Linear Classification"></a>Linear Classification</h2><ul><li>Loss function</li><li>Optimization</li><li>Convnets</li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习入门（一）</title>
      <link href="/posts/35246/"/>
      <url>/posts/35246/</url>
      
        <content type="html"><![CDATA[<h2 id="单变量线性回归"><a href="#单变量线性回归" class="headerlink" title="单变量线性回归"></a>单变量线性回归</h2><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><ol><li><p>导入所需模块 </p></li><li><p>使用random随机生成数据  </p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">100</span>, <span class="number">30</span>)</span><br><span class="line">y = <span class="number">3</span>*x + <span class="number">7</span> + np.random.randint(<span class="number">30</span>)*<span class="number">6</span></span><br></pre></td></tr></table></figure><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/ghblog-git/img/images/model01.png"  alt="散点图"></p><h3 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()  <span class="comment"># 顺序模型</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, input_dim=<span class="number">1</span>))</span><br><span class="line">model.summary()</span><br><span class="line">Model: <span class="string">"sequential_1"</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">dense_1 (Dense)              (<span class="literal">None</span>, <span class="number">1</span>)                 <span class="number">2</span>    </span><br><span class="line">=================================================================     </span><br><span class="line">Total params: <span class="number">2</span></span><br><span class="line">Trainable params: <span class="number">2</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">____________________________</span><br></pre></td></tr></table></figure><h3 id="编译模型"><a href="#编译模型" class="headerlink" title="编译模型"></a>编译模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">"adam"</span>,  <span class="comment"># 优化算法为adam</span></span><br><span class="line">    loss=<span class="string">"mse"</span>         <span class="comment"># 损失函数为均方差</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x, y, epochs=<span class="number">9000</span>)</span><br><span class="line">Epoch <span class="number">7524</span>/<span class="number">9000</span></span><br><span class="line"><span class="number">30</span>/<span class="number">30</span> [==============================] - <span class="number">0</span>s <span class="number">100</span>us/step - loss: <span class="number">2890.6289</span></span><br><span class="line">Epoch <span class="number">7525</span>/<span class="number">9000</span></span><br><span class="line"><span class="number">30</span>/<span class="number">30</span> [==============================] - <span class="number">0</span>s <span class="number">66</span>us/step - loss: <span class="number">2890.5745</span></span><br><span class="line">Epoch <span class="number">7526</span>/<span class="number">9000</span></span><br><span class="line"><span class="number">30</span>/<span class="number">30</span> [==============================] - <span class="number">0</span>s <span class="number">66</span>us/step - loss: <span class="number">2890.5193</span></span><br><span class="line">Epoch <span class="number">7527</span>/<span class="number">9000</span></span><br><span class="line"><span class="number">30</span>/<span class="number">30</span> [==============================] - <span class="number">0</span>s <span class="number">100</span>us/step - loss: <span class="number">2890.4651</span></span><br></pre></td></tr></table></figure><h3 id="结果对比"><a href="#结果对比" class="headerlink" title="结果对比"></a>结果对比</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(x, y, c=<span class="string">'r'</span>)</span><br><span class="line">plt.plot(x, model.predict(x))</span><br></pre></td></tr></table></figure><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/ghblog-git/img/images/model02.png"  alt=""></p><h2 id="多变量线性回归"><a href="#多变量线性回归" class="headerlink" title="多变量线性回归"></a>多变量线性回归</h2><p>pandas读取数据并预处理  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">"./dataset/线性回归.csv"</span>)</span><br><span class="line">x = data[data.columns[<span class="number">1</span>: <span class="number">-1</span>]]</span><br><span class="line">y = data.iloc[:, <span class="number">-1</span>]</span><br></pre></td></tr></table></figure><h3 id="建立模型-1"><a href="#建立模型-1" class="headerlink" title="建立模型"></a>建立模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, input_dim=<span class="number">3</span>))   y_pred = w1*x1 + w2+x2 + w3*x3 +b</span><br><span class="line">model.summary()</span><br><span class="line">Model: <span class="string">"sequential_2"</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">dense_1 (Dense)              (<span class="literal">None</span>, <span class="number">1</span>)                 <span class="number">4</span>         </span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">4</span></span><br><span class="line">Trainable params: <span class="number">4</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">____________________________</span><br></pre></td></tr></table></figure><h3 id="编译模型-1"><a href="#编译模型-1" class="headerlink" title="编译模型"></a>编译模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'mse'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x, y, epochs=<span class="number">2000</span>)</span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">2000</span></span><br><span class="line"><span class="number">200</span>/<span class="number">200</span> [==============================] - <span class="number">0</span>s <span class="number">30</span>us/step - loss: <span class="number">2.8109</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">2000</span></span><br><span class="line"><span class="number">200</span>/<span class="number">200</span> [==============================] - <span class="number">0</span>s <span class="number">35</span>us/step - loss: <span class="number">2.8055</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">2000</span></span><br><span class="line"><span class="number">200</span>/<span class="number">200</span> [==============================] - <span class="number">0</span>s <span class="number">40</span>us/step - loss: <span class="number">2.8167</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">2000</span></span><br><span class="line"><span class="number">200</span>/<span class="number">200</span> [==============================] - <span class="number">0</span>s <span class="number">55</span>us/step - loss: <span class="number">2.8635</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> keras </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程面向对象爬取表情包</title>
      <link href="/posts/12185/"/>
      <url>/posts/12185/</url>
      
        <content type="html"><![CDATA[<p>爬取整个网站的表情包，快活吧！<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/ghblog-git/img/images/model03.gif"  alt=""></p><p>下面附上源代码 </p><p><em>如果没有python环境的小伙伴也不用担心，</em><br><em>我把代码打包成了exe文件，开箱即用。 百度云链接放在文章末尾。</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     :   2020/5/29 19:40</span></span><br><span class="line"><span class="comment"># @Author   :   gh</span></span><br><span class="line"><span class="comment"># @File     :   img.py</span></span><br><span class="line"><span class="comment"># @Software :   PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BASE_URL = <span class="string">'http://www.doutula.com/photo/list'</span> </span><br><span class="line">PROXY_POOL_URL = <span class="string">'http://localhost:5555/random'</span>   <span class="comment"># 代理池 爬取此站不需要</span></span><br><span class="line">TOTAL_PAGE = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    format=<span class="string">'%(asctime)s - %(levelname)s: %(message)s'</span>)</span><br><span class="line"></span><br><span class="line">RESULTS_DIR = <span class="string">'images/'</span></span><br><span class="line">os.path.exists(RESULTS_DIR) <span class="keyword">or</span> os.makedirs(RESULTS_DIR)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">User_Agent</span><span class="params">()</span>:</span></span><br><span class="line">    User_Agent = [</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20"</span>,</span><br><span class="line">        <span class="string">"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.11 TaoBrowser/2.0 Safari/536.11"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.71 Safari/537.1 LBBROWSER"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; LBBROWSER)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E; LBBROWSER)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 LBBROWSER"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; 360SE)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (iPad; U; CPU OS 4_2_1 like Mac OS X; zh-cn) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8C148 Safari/6533.18.5"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0b13pre) Gecko/20110307 Firefox/4.0b13pre"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:16.0) Gecko/20100101 Firefox/16.0"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11"</span>,</span><br><span class="line">        <span class="string">"Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10"</span></span><br><span class="line">    ]</span><br><span class="line">    this_ua = random.choice(User_Agent)</span><br><span class="line">    <span class="keyword">global</span> headers</span><br><span class="line">    headers = &#123;<span class="string">"User-Agent"</span>: this_ua</span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">    创建生产者类  并把页面url和每个图片的url队列交给生产者类去解析</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, page_queue, img_queue, *args, **kwargs)</span>:</span></span><br><span class="line">        super(Producer, self).__init__(*args, **kwargs)</span><br><span class="line">        self.page_queue = page_queue</span><br><span class="line">        self.img_queue = img_queue</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> self.page_queue.empty():</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            url = self.page_queue.get()</span><br><span class="line">            self.parse_page(url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        res = requests.get(url, headers=headers)</span><br><span class="line">        text = res.text</span><br><span class="line">        html = etree.HTML(text)</span><br><span class="line">        img_tags = html.xpath(<span class="string">'//div[@class="page-content text-center"]//img[@class!="gif"]'</span>)</span><br><span class="line">        <span class="keyword">for</span> img_tag <span class="keyword">in</span> img_tags:</span><br><span class="line">            img_url = img_tag.get(<span class="string">'data-original'</span>)</span><br><span class="line">            alt = img_tag.get(<span class="string">'alt'</span>)</span><br><span class="line">            new_alt = re.sub(<span class="string">'r[\?？！!\.，。]'</span>,<span class="string">''</span>, alt)   </span><br><span class="line">            suffix = os.path.splitext(img_url)[<span class="number">1</span>]  <span class="comment"># 用来分离.前后的数据</span></span><br><span class="line">            filename = new_alt + suffix</span><br><span class="line">            self.img_queue.put((img_url, filename))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, page_queue, img_queue, *args, **kwargs)</span>:</span></span><br><span class="line">        super(Consumer, self).__init__(*args, **kwargs)</span><br><span class="line">        self.page_queue = page_queue</span><br><span class="line">        self.img_queue = img_queue</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> self.img_queue.empty() <span class="keyword">and</span> self.page_queue.empty():</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            img_url, filename = self.img_queue.get()</span><br><span class="line">            request.urlretrieve(img_url, RESULTS_DIR+filename)</span><br><span class="line">            logging.info(filename + <span class="string">'  download completes·····   '</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_url</span><span class="params">(page)</span>:</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">f'<span class="subst">&#123;BASE_URL&#125;</span>/?page=<span class="subst">&#123;page&#125;</span>'</span></span><br><span class="line">    <span class="keyword">return</span> url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    User_Agent()</span><br><span class="line">    page_queue = Queue(<span class="number">1000</span>)</span><br><span class="line">    img_queue = Queue(<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, TOTAL_PAGE):</span><br><span class="line">        url = get_url(page)</span><br><span class="line">        page_queue.put(url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        t = Producer(page_queue, img_queue)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        t = Consumer(page_queue, img_queue)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>链接：<a href="https://pan.baidu.com/s/1QRFjGecsMZ0iF5_g8WK_Hw" target="_blank" rel="noopener">https://pan.baidu.com/s/1QRFjGecsMZ0iF5_g8WK_Hw</a><br>提取码：h5z3</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP/IP各层详解</title>
      <link href="/posts/53690/"/>
      <url>/posts/53690/</url>
      
        <content type="html"><![CDATA[<h2 id="TCP-IP各层详解"><a href="#TCP-IP各层详解" class="headerlink" title="TCP/IP各层详解"></a>TCP/IP各层详解</h2><h3 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h3><p>物理层由来：上面提到，孤立的计算机之间要想一起玩，就必须接入internet，言外之意就是计算机之间必须完成组网。  </p><p><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/image_1c1phulig10ftmjl914m11l7g37.png"  alt=""></p><p>物理层功能：主要是基于电器特性发送高低电压(电信号)，高电压对应数字1，低电压对应数字0.  </p><h3 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h3><p>数据链路层由来：单纯的电信号0和1没有任何意义，必须规定电信号多少位一组，每组什么意思</p><p>数据链路层的功能：定义了电信号的分组方式</p><h4 id="以太网协议："><a href="#以太网协议：" class="headerlink" title="以太网协议："></a>以太网协议：</h4><p>早期的时候各个公司都有自己的分组方式，后来形成了统一的标准，即以太网协议ethernet</p><p>ethernet规定</p><p>一组电信号构成一个数据包，叫做‘帧’<br>每一数据帧分成：报头head和数据data两部分<br>head data<br>head包含：(固定18个字节)</p><p>发送者／源地址，6个字节<br>接收者／目标地址，6个字节<br>数据类型，6个字节<br>data包含：(最短46字节，最长1500字节)</p><p>数据包的具体内容<br>head长度＋data长度＝最短64字节，最长1518字节，超过最大限制就分片发送</p><h4 id="mac地址："><a href="#mac地址：" class="headerlink" title="mac地址："></a>mac地址：</h4><p>head中包含的源和目标地址由来：ethernet规定接入internet的设备都必须具备网卡，发送端和接收端的地址便是指网卡的地址，即mac地址</p><p>mac地址：每块网卡出厂时都被烧制上一个世界唯一的mac地址，长度为48位2进制，通常由12位16进制数表示（前六位是厂商编号，后六位是流水线号）<br><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/image_1c1phvbie1089aas488136h1b3t44.png"  alt="">  </p><h4 id="广播："><a href="#广播：" class="headerlink" title="广播："></a>广播：</h4><p>有了mac地址，同一网络内的两台主机就可以通信了（一台主机通过arp协议获取另外一台主机的mac地址）</p><p>ethernet采用最原始的方式，广播的方式进行通信，即计算机通信基本靠吼</p><h3 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h3><p>网络层由来：有了ethernet、mac地址、广播的发送方式，世界上的计算机就可以彼此通信了，问题是世界范围的互联网是由</p><p>一个个彼此隔离的小的局域网组成的，那么如果所有的通信都采用以太网的广播方式，那么一台机器发送的包全世界都会收到，</p><p>这就不仅仅是效率低的问题了，这会是一种灾难</p><p>上图结论：必须找出一种方法来区分哪些计算机属于同一广播域，哪些不是，如果是就采用广播的方式发送，如果不是，</p><p>就采用路由的方式（向不同广播域／子网分发数据包），mac地址是无法区分的，它只跟厂商有关</p><p>网络层功能：引入一套新的地址用来区分不同的广播域／子网，这套地址即网络地址</p><h4 id="IP协议："><a href="#IP协议：" class="headerlink" title="IP协议："></a>IP协议：</h4><p>规定网络地址的协议叫ip协议，它定义的地址称之为ip地址，广泛采用的v4版本即ipv4，它规定网络地址由32位2进制表示<br>范围0.0.0.0-255.255.255.255<br>一个ip地址通常写成四段十进制数，例：172.16.10.1</p><h4 id="子网掩码"><a href="#子网掩码" class="headerlink" title="子网掩码"></a>子网掩码</h4><p>所谓”子网掩码”，就是表示子网络特征的一个参数。它在形式上等同于IP地址，也是一个32位二进制数字，它的网络部分全部为1，主机部分全部为0。比如，IP地址172.16.10.1，如果已知网络部分是前24位，主机部分是后8位，那么子网络掩码就是11111111.11111111.11111111.00000000，写成十进制就是255.255.255.0。</p><p>子网掩码是用来标识一个IP地址的哪些位是代表网络位，以及哪些位是代表主机位。子网掩码不能单独存在，它必须结合IP地址一起使用。子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分。</p><p>蒙蔽的你肯定想问，我要区分网络位和主机位干鬼用？</p><p>这就像寄信，你给你的南方姑娘寄信，她肉身在厦门，详细地址是厦门鼓浪屿三街27号，那网络位就相当于城市，详细地址就是主机位，网络位帮你定位到城市，主机位帮你找到你的南方姑娘。 路由器通过子网掩码来确定哪些是网络位，哪些是主机位</p><p>区分网络位和主机位是为了划分子网，就是把一个大网络分成多个小网络，为什么要分子网呢?</p><p>广播风暴：6万台主机在一个网段里，通信基本靠吼，任何一个人要吼一嗓子，6万多个人必须被动听着，一会你的网络就瘫痪啦。</p><p>地址浪费：运营商在公网上有很多级联的路由器，有时候2个路由器之间只会用掉几个IP,如果不进行子网划分，那同网段的其它主机也就都不能用了。举例两个级联路由器的接口ip分别为222.34.24.12/24,222.34.24.13/24, 此可承载255个主机的网段只用了2个IP,那其它的就全浪费了，因为不能再分配给别人。<br>划分子网本质上就是借主机位到给网络位，每借一位主机位，这个网段的可分配主机就会越少，比如192.168.1.0/24可用主机255个，借一位变成192.168.1.0/25，那可用主机就从255-128=127个了（从最大的值开始借），再借一位192.168.1.0/26,那可用主机数就变成了255-(128+64)=63个啦</p><h5 id="IP地址分类："><a href="#IP地址分类：" class="headerlink" title="IP地址分类："></a>IP地址分类：</h5><p>IP地址根据网络ID的不同分为5种类型，A类地址、B类地址、C类地址、D类地址和E类地址。</p><p>A类IP地址：一个A类IP地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”， 地址范围从1.0.0.0 到126.0.0.0。可用的A类网络有126个，每个网络能容纳1亿多个主机。</p><p>B类IP地址 ：一个B类IP地址由2个字节的网络地址和2个字节的主机地址组成，网络地址的最高位必须是“10”，地址范围从128.0.0.0到191.255.255.255。可用的B类网络有16382个，每个网络能容纳6万多个主机 。</p><p>C类IP地址：一个C类IP地址由3字节的网络地址和1字节的主机地址组成，网络地址的最高位必须是“110”。范围从192.0.0.0到223.255.255.255。C类网络可达209万余个，每个网络能容纳254个主机。</p><p>D类地址用于多点广播（Multicast）： D类IP地址第一个字节以“lll0”开始，它是一个专门保留的地址。它并不指向特定的网络，目前这一类地址被用在多点广播（Multicast）中。多点广播地址用来一次寻址一组计算机，它标识共享同一协议的一组计算机。</p><p>E类IP地址 以“llll0”开始，为将来使用保留。</p><p>全零（“0．0．0．0”）地址对应于当前主机。</p><p>全“1”的IP地址（“255．255．255．255”）是当前子网的广播地址。</p><p>回环地址(127.0.0.1) 又称为本机地址，那它跟0.0.0.0是什么区别呢？那得先了解回环接口</p><p>环回接口（loopback）。平时我们用127.0.0.1来尝试自己的机器服务器好使不好使。走的就是这个loopback接口。对于环回接口，有如下三点值得注意:</p><p>传给环回地址（一般是127.0.0.1）的任何数据均作为IP输入。<br>传给广播地址或多播地址的数据报复制一份传给环回接口，然后送到以太网上。这是 因为广播传送和多播传送的定义包含主机本身。<br>任何传给该主机IP地址的数据均送到环回接口。<br>IP报文<br>IP协议是TCP/IP协议的核心，所有的TCP，UDP，IMCP，IGCP的数据都以IP数据格式传输，要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制－－这被认为是上层协议－－TCP或UDP要做的事情。所以这也就出现了TCP是一个可靠的协议，而UDP就没有那么可靠的区别。这是后话，暂且不提。</p><p>IP协议头</p><p>挨个解释它是教科书的活计，我感兴趣的只是那八位的TTL字段，还记得这个字段是做什么的么？这个字段规定该数据包在穿过多少个路由之后才会被抛弃(这里就体现出来IP协议包的不可靠性，它不保证数据被送达)，某个ip数据包每穿过一个路由器，该数据包的TTL数值就会减少1，当该数据包的TTL成为零，它就会被自动抛弃。这个字段的最大值也就是255，也就是说一个协议包也就在路由器里面穿行255次就会被抛弃了，根据系统的不同，这个数字也不一样，一般是32或者是64</p><p>ARP协议<br>arp协议由来：计算机通信基本靠吼，即广播的方式，所有上层的包到最后都要封装上以太网头，然后通过以太网协议发送，在谈及以太网协议时候，我门了解到</p><p>通信是基于mac的广播方式实现，计算机在发包时，获取自身的mac是容易的，如何获取目标主机的mac，就需要通过arp协议</p><p>arp协议功能：广播的方式发送数据包，获取目标主机的mac地址</p><p>协议工作方式：每台主机ip都是已知的</p><p>例如：主机172.16.10.10/24访问172.16.10.11/24</p><p>一：首先通过ip地址和子网掩码区分出自己所处的子网<br><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/FG%25H6W5WCUQ0XY(IS2LWC%24M.png"  alt="">  </p><p>二：分析172.16.10.10/24与172.16.10.11/24处于同一网络(如果不是同一网络，那么下表中目标ip为172.16.10.1,通过arp获取的是网关的mac)<br><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/%40D%24%7BQ9%7B%7BEN~%246DBA%7BB~BZ%5B6.png"  alt="">  </p><p>三：这个包会以广播的方式在发送端所处的子网内传输，所有主机接收后拆开包，发现目标ip为自己的，就响应，返回自己的mac</p><p>前面讲到了，IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。</p><p>当传送IP数据包发生错误－－比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会.</p><p>我们一般主要用ICMP协议检测网络是否通畅，基于ICMP协议的工具主要有ping 和traceroute </p><p>ping这个单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请 求，受到请求的主机则用类型码为8的ICMP回应。ping程序来计算间隔时间，并计算有多少个包被送达。用户就可以判断网络大致的情况。我们可以看到， ping给出来了传送的时间和TTL的数据。 </p><p>traceroute<br>用来查看从当前主机到某地址一共经过多少跳路由</p><h3 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h3><p>传输层的由来：网络层的ip帮我们区分子网，以太网层的mac帮我们找到主机，然后大家使用的都是应用程序，你的电脑上可能同时开启qq，暴风影音，迅雷等多个应用程序，</p><p>那么我们通过ip和mac找到了一台特定的主机，如何标识这台主机上的应用程序呢？答案就是端口，端口即应用程序与网卡关联的编号。</p><p>传输层功能：建立端口到端口的通信</p><p>补充：端口范围0-65535，0-1023为系统占用端口</p><p>传输层有两种协议，TCP和UDP,见下图  </p><p><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/1.png"  alt=""></p><p>tcp协议<br>可靠传输，TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。</p><p><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/2.png"  alt=""></p><p>为什么tcp是可靠的数据传输呢？</p><p>最可靠的方式就是只要不得到确认，就重新发送数据报，直到得到对方的确认为止。<br>tcp报文<br><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/3.png"  alt="">  </p><p>tcp的3次握手和4四挥手</p><p><img src="/" class="lazyload" data-src="http://static.zybuluo.com/agocan/gbg90sa2fn94tkk3asobet6u/image_1c1phb5ao10jb183v1l3i1psgo6037.png"  alt=""></p><p>udp协议<br>不可靠传输，”报头”部分一共只有8个字节，总长度不超过65,535字节，正好放进一个IP数据包。<br><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/5.png"  alt="">  </p><p>总结<br>TCP协议虽然安全性很高，但是网络开销大，而UDP协议虽然没有提供安全机制，但是网络开销小，在现在这个网络安全已经相对较高的情况下，为了保证传输的速率，我们一般还是会优先考虑UDP协议！</p><h3 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h3>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python网络编程(一)</title>
      <link href="/posts/47142/"/>
      <url>/posts/47142/</url>
      
        <content type="html"><![CDATA[<h2 id="C-S架构"><a href="#C-S架构" class="headerlink" title="C/S架构"></a>C/S架构</h2><p>C指的是client(客户端)，s指的是server(服务端)，  </p><h2 id="计算机基础知识"><a href="#计算机基础知识" class="headerlink" title="计算机基础知识"></a>计算机基础知识</h2><p>客户端软件想要基于网络发送一条消息给服务端软件，流程是：</p><ol><li><p>客户端软件产生数据，存放于客户端软件的内存中，然后调用接口将自己内存中的数据发送／拷贝给操作系统内存  </p></li><li><p>客户端操作系统收到数据后，按照客户端软件指定的规则（即协议）、调用网卡发送数据  </p></li><li><p>网络传输数据  </p></li><li><p>服务端软件调用系统接口，想要将数据从操作系统内存拷贝到自己的内存中  </p></li><li><p>服务端操作系统收到4的指令后，使用与客户端相同的规则（即协议）从网卡接收到数据，然后拷贝给服务端软件  </p></li></ol><p><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80.png"  alt="">  </p><h2 id="什么是网络"><a href="#什么是网络" class="headerlink" title="什么是网络"></a>什么是网络</h2><ol><li><p>硬件上安装好操作系统，再装上软件便可使用，但是只能自己使用，彼此孤立。  </p></li><li><p>计算机之间的通信首先要有物理链接介质，比如网线，交换机，路由器等网络设备。 通信的线路建好之后，只是物理层面有了可以承载数据的介质，要想通信，还需要我们按照某种规则组织我们的数据，这样对方在接收到数据后就可以按照相同的规则去解析出数据，这里说的规则指的就是：中国有很多地区，不同的地区有不同的方言，为了全中国人都可以听懂，大家统一讲普通话。  </p></li><li><p>然而只实现国家之内的通信是不够的，国与国之间的通信怎么办呢？我们需要一个世界通用的通信标准，这个标准称之为互联网协议。  </p></li><li><p>可以很明确地说：互联网协议就是计算机界的英语， <font color="red">网络</font>就是<font color="red">物理链接介质+互联网协议</font>。<br>我们需要做的是，让全世界的计算机都学会互联网协议，这样任意一台计算机在发消息时都严格按照协议规定的格式去组织数据，接收方就可以按照相同的协议解析出结果了，这就实现了全世界的计算机都能无障碍通信。   </p></li><li><p>按照功能不同，人们将互联网协议分为osi七层或tcp/ip五层或tcp/ip四层（我们只需要掌握tcp/ip五层协议即可），这种分层就好比是学习英语的几个阶段，每个阶段应该掌握专门的技能或者说完成特定的任务，比如：1、学音标 2、学单词 3、学语法 4、写作文。。。  </p></li></ol><p><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/6.1-osi.png"  alt="">  </p><p><img src="/" class="lazyload" data-src="https://book.apeland.cn/media/images/2019/06/24/6.1-osi-2.png"  alt="每层对应的设备">  </p><h2 id="TCP-IP介绍"><a href="#TCP-IP介绍" class="headerlink" title="TCP/IP介绍"></a>TCP/IP介绍</h2><h3 id="什么是TCP-IP"><a href="#什么是TCP-IP" class="headerlink" title="什么是TCP/IP?"></a>什么是TCP/IP?</h3><p>Transmission Control Protocol/Internet Protocol的简写，中译名为传输控制协议/因特网互联协议，又名网络通讯协议，是Internet最基本的协议、Internet国际互联网络的基础。  </p><h3 id="TCP-IP的起源"><a href="#TCP-IP的起源" class="headerlink" title="TCP/IP的起源"></a>TCP/IP的起源</h3><ol><li><p>20世纪50年代末，正处于冷战时期。当时美国军方为了自己的计算机网络在受到袭击时，即使部分网络被摧毁，其余部分仍能保持通信联系，便由美国国防部的高级研究计划局（ARPA）建设了一个军用网，叫做“阿帕网”（ARPAnet）。阿帕网于1969年正式启用，当时仅连接了4台计算机，供科学家们进行计算机联网实验用，这就是因特网的前身。</p></li><li><p>到70年代，ARPAnet已经有了好几十个计算机网络，但是每个网络只能在网络内部的计算机之间互联通信，不同计算机网络之间仍然不能互通。为此， ARPA又设立了新的研究项目，支持学术界和工业界进行有关的研究，研究的主要内容就是想用一种新的方法将不同的计算机局域网互联，形成“互联网”。研究人员称之为“internetwork”，简称“Internet”，这个名词就一直沿用到现在。</p></li><li><p>终于到1974年，TCP/IP诞生啦，TCP/IP有一个非常重要的特点，就是开放性，即TCP/IP的规范和Internet的技术都是公开的。目的就是使任何厂家生产的计算机都能相互通信，使Internet成为一个开放的系统，这正是后来Internet得到飞速发展的重要原因。   </p></li></ol><h3 id="OSI七层模型"><a href="#OSI七层模型" class="headerlink" title="OSI七层模型"></a>OSI七层模型</h3><ol><li>美国国防部在开发tcp/ip的同时，还有一些其它大厂商也开发出了自己的网络体系，实际上世界上第一个网络体系结构由IBM公司提出（也是74年，比TCP/IP略早，SNA），以后其他公司也相继提出自己的网络体系结构如：Digital公司的DNA，美国国防部的TCP/IP等，多种网络体系结构并存，其结果是若采用IBM的结构，只能选用IBM的产品，只能与同种结构的网络互联。</li><li>这就像中国人说中文，美国人说英语，日本人说日本话一样，同一国家的人沟通没问题，但不同国家之间的人没法通信。为了解决网络通信中这样不互通的问题，国际标准化组织ISO于1977年成立了一个委员会，在现有网络的基础上，提出了不基于具体机型、操作系统或公司的网络体系结构，称为开放系统互联模型。</li><li>OSI/RM模型(Open System Interconnection / Reference Model)的设计目的是成为一个所有计算机厂商都能实现的开放网络模型，来克服使用众多私有网络模型所带来的困难和低效性。  </li></ol>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>c primer plus notes</title>
      <link href="/posts/18555/"/>
      <url>/posts/18555/</url>
      
        <content type="html"><![CDATA[<h2 id="头文件"><a href="#头文件" class="headerlink" title="头文件"></a>头文件</h2><p>include             include代表将文件拷贝过来当作文本文件解析<br>include<stdlib.h>  &lt;&gt;代表系统目录下查找文件<br>include”stdlib.h”  “”代表先在当前目录查找 若当前目录没有则去系统目录查找  </p><p>return之后的语句不会执行  </p><h2 id="C语言程序结构"><a href="#C语言程序结构" class="headerlink" title="C语言程序结构"></a>C语言程序结构</h2><p>同步执行：  后面的语句要等当前退出。<br>异步执行：  不等待退出可以执行。   </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#define _CRT_SECURE_NO_WARNINGS</span><br><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;stdlib.h&gt;</span><br><span class="line">#include&lt;Windows.h&gt;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    char str[100] &#x3D; &#123; 0 &#125;;</span><br><span class="line">    &#x2F;&#x2F; printf(&quot;Please input your instructions\n&quot;);</span><br><span class="line">    &#x2F;&#x2F; scanf(&quot;%s&quot;, str);</span><br><span class="line">    &#x2F;&#x2F; printf(&quot;The instructions you are going to execute %s&quot;, str);</span><br><span class="line">    &#x2F;&#x2F; system(str);</span><br><span class="line"></span><br><span class="line">    system(&quot;start notepad&quot;);  &#x2F;&#x2F; 后面的语句要等当前退出。</span><br><span class="line">    system(&quot;start notepad&quot;);  &#x2F;&#x2F; 加上start后，不等待退出可以执行。</span><br><span class="line">    Sleep(5000);</span><br><span class="line">    system(&quot;taskkill &#x2F;f &#x2F;im notepad.exe&quot;);</span><br><span class="line">    system(&quot;pause&quot;);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;stdlib.h&gt;</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">    system(&quot;notepad&quot;);</span><br><span class="line">    main() &#x2F;&#x2F; 递归main 死循环</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>预处理优先于编译，又叫预编译  </p><ol><li>预处理指令 例如 包含头文件  </li><li>全局声明  </li><li>函数定义</li></ol><h2 id="编译-链接"><a href="#编译-链接" class="headerlink" title="编译 链接"></a>编译 链接</h2><p>编辑源代码： 代码在.c和.h文件中写好了以后，编译成.obj<br>编译源文件： 代码被编译成二进制文件.obj后，打包一些调用的库，<br>链接生成应用程序：链接成.exe可执行文件，从obj链接成exe，如果调试出现问题。返回原代码编辑  </p><p>gcc命令行操作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gcc -E  预编译</span><br><span class="line">gcc -s  转汇编</span><br><span class="line">gcc -c  编译</span><br></pre></td></tr></table></figure></p><h2 id="数据结构-amp-算法"><a href="#数据结构-amp-算法" class="headerlink" title="数据结构&amp;算法"></a>数据结构&amp;算法</h2><p>数据结构： 二叉树，队列，栈，红黑树，链表等等<br>算法： 快速排序算法，冒泡排序算法，选择排序算法等等  </p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">    int a &#x3D; 10;   &#x2F;&#x2F; 10放在代码区的符号表，然后在寄存器产生 </span><br><span class="line">    printf(&quot;%p&quot;,&amp;a);</span><br><span class="line">    getchar();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>c语言嵌入汇编<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">    int a;</span><br><span class="line">    printf(&quot;%p&quot;,&amp;a);</span><br><span class="line"></span><br><span class="line">    _asm</span><br><span class="line">    &#123;</span><br><span class="line">        mov eax, 10</span><br><span class="line">        mov a, eax</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    getchar();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>变量赋值都是通过cpu的寄存器实现  </p><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p>c语言的基本数据类型： 整型，浮点型，字符型。 然后就是复合数据类型。（数组，结构体，公用体）  </p><p>对二维数组取值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># include&lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">    int a[3][4] &#x3D; &#123;</span><br><span class="line">        &#123;1, 2, 3, 4&#125;,</span><br><span class="line">        &#123;5, 6, 7, 8&#125;,</span><br><span class="line">        &#123;9, 10, 11, 12&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    int i, j;</span><br><span class="line"></span><br><span class="line">    for( i &#x3D; 0; i &lt; 3; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for ( j &#x3D; 0; j &lt; 4; j++)</span><br><span class="line">        </span><br><span class="line">            printf(&quot;%d\n&quot;, a[i][j]);</span><br><span class="line">        </span><br><span class="line">    &#125;;</span><br><span class="line">    return 0;</span><br><span class="line">        </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h2><p>动态内存分配<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># include&lt;stdio.h&gt;</span><br><span class="line"># include&lt;malloc.h&gt;</span><br><span class="line"></span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">    int len;</span><br><span class="line">    int *pArr;</span><br><span class="line">    int i;</span><br><span class="line"></span><br><span class="line">    printf(&quot;please input the length of array:\n&quot;);</span><br><span class="line">    scanf(&quot;%d\n&quot;, &amp;len);</span><br><span class="line">    pArr &#x3D; (int *)malloc(4 * len);</span><br><span class="line">   </span><br><span class="line">    printf(&quot;please input the content of array:\n&quot;);</span><br><span class="line">   for ( i &#x3D; 0; i &lt; len; i++)</span><br><span class="line">   &#123;</span><br><span class="line">       scanf(&quot;%d\n&quot;, (pArr + i));</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   free(pArr);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h2><p>超简陋学生管理系统<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"># include&lt;stdio.h&gt;</span><br><span class="line"># include&lt;string.h&gt;</span><br><span class="line"></span><br><span class="line">void Input_Stu();</span><br><span class="line">void Output_Stu();</span><br><span class="line">void Output_Stu_P();</span><br><span class="line"></span><br><span class="line">struct Student </span><br><span class="line">    &#123;</span><br><span class="line">        char name[20];</span><br><span class="line">        int age;</span><br><span class="line">        char sex;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    </span><br><span class="line">    struct Student stu1;</span><br><span class="line">    Input_Stu(&amp;stu1);</span><br><span class="line">    &#x2F;&#x2F; Output_Stu(stu1);</span><br><span class="line">    Output_Stu_P(&amp;stu1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Input_Stu(struct Student *pstu)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; strcpy(pstu-&gt;name, &quot;lisa&quot;);</span><br><span class="line">    &#x2F;&#x2F; pstu-&gt;age &#x3D; 18;</span><br><span class="line">    &#x2F;&#x2F; pstu-&gt;sex &#x3D; &#39;F&#39;;</span><br><span class="line">    &#x2F;&#x2F; strcpy((*pstu).name, &quot;lisa&quot;);</span><br><span class="line">    printf(&quot;please input\n&quot;);</span><br><span class="line">    (*pstu).age &#x3D; 18;</span><br><span class="line">    (*pstu).sex &#x3D; &#39;F&#39;;</span><br><span class="line">    scanf(&quot;%s&quot;, &amp;((*pstu).name));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Output_Stu(struct Student stu)</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;name: %s, age: %d, sex: %c&quot;, stu.name, stu.age, stu.sex);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Output_Stu_P(struct Student *pstu)</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;name: %s, age: %d, sex: %c&quot;, pstu-&gt;name, pstu-&gt;age, pstu-&gt;sex);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> c语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构学习笔记（一）</title>
      <link href="/posts/26652/"/>
      <url>/posts/26652/</url>
      
        <content type="html"><![CDATA[<h2 id="数据-amp-数据元素"><a href="#数据-amp-数据元素" class="headerlink" title="数据&amp;数据元素"></a>数据&amp;数据元素</h2><p><strong>数据</strong>是信息的载体，是描述客观事物属性的数，字符及所有能输入到计算机中并被计算机识别和<br>处理的符号的集合。数据是计算机加工程序的原料。  </p><p><strong>数据元素</strong>是数据的基本单位，通常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成，数据项是构成数据元素的不可分割的最小单位。</p><h2 id="数据结构-amp-数据对象"><a href="#数据结构-amp-数据对象" class="headerlink" title="数据结构&amp;数据对象"></a>数据结构&amp;数据对象</h2><p><strong>数据结构</strong>是相互之间存在一种或多种特定关系的数据元素集合。  </p><p><strong>数据对象</strong>是具有相同性质的元素的集合，是数据的一个子集。  </p><h2 id="数据类型-amp-抽象数据类型"><a href="#数据类型-amp-抽象数据类型" class="headerlink" title="数据类型&amp;抽象数据类型"></a>数据类型&amp;抽象数据类型</h2><p><strong>数据类型</strong>是一个值的集合和定义在此集合上的一组操作的总称。  </p><ol><li>原子类型： 其值不可再分的数据类型。</li><li>结构类型： 其值可以再分解为若干成分的数据类型。  </li></ol><p><strong>抽象数据类型(Abstract Data Type，ADT)</strong>是抽象数据组织及与之相关的操作。</p><h2 id="数据结构三要素"><a href="#数据结构三要素" class="headerlink" title="数据结构三要素"></a>数据结构三要素</h2><ol><li><p>逻辑结构</p><ul><li>集合： 各个元素同属一个集合，别无其它关系。</li><li>线性结构： 数据元素之间是一对一关系。除了第一个元素，所有元素都有唯一前驱，除了最后一个元素，所有元素都有唯一后继。</li><li>树形结构： 数据元素之间是一对多的关系。</li><li>图状结构(网状结构)： 数据元素之间是多对多关系。</li></ul></li><li><p>物理结构（存储结构）</p><ul><li>顺序存储： 把逻辑上相邻的元素存储在物理位置上也相邻的存储单元中，元素之间的关系由存储单元的邻接关系来体现。</li><li>链式存储： 逻辑上相邻的元素在物理位置上可以不相邻，借助元素存储地址的指针来表示元素之间的逻辑关系。</li><li>索引存储： 在存储元素信息的同时，还建立附加的索引表。索引表中的每项称为索引项，索引项的一般形式是（关键字，地址）。</li><li>散列存储： 根据元素的关键字直接计算出该元素的存储地址，又称哈希存储。</li></ul></li><li><p>数据的运算</p><ul><li>施加在数据上的运算包括运算的定义和实现。</li><li>运算的定义： 是针对逻辑结构的。</li><li>运算的功能： 运算的实现是针对存储结构的。</li></ul></li></ol><p>总结：</p><ol><li>若采用<font color="red">顺序存储</font>，则各个数据元素在物理上必须是<font color="red"> 连续的</font>，若采用<font color="red"> 非顺序存储</font>，则各个数据元素在物理上可以是<font color="red"> 离散的</font>。</li><li>数据的<font color="red"> 存储结构</font>会 <font color="red">影响存储空间分配的方便程度</font>。  </li><li>数据的 <font color="red"> 存储结构</font>会 <font color="red">影响对数据运算的速度</font>。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu20.04 美化</title>
      <link href="/posts/63991/"/>
      <url>/posts/63991/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><blockquote><p>最近更新了ubuntu的最新 系统，升级到了20.04。 先看一下他的新特性吧！    </p><blockquote><p>   首先是主题变化，Yaru 会有一个从亮到暗的主题变化可选，该主题下的复选框、单选按钮以及滑块和进度条等，都不再呈蓝色或绿色，而以紫色取代之。从绿色切换到紫色，整体上减少了纷杂的色彩，同时也不破坏 Ubuntu 本身的和谐。</p><p>   其次，Ubuntu 社区的另一个期待已久的需求也将得到满足，系统将删除预装的 Amazon 应用。Ubuntu 上的 Amazon 图标一直就挂在桌面，这早已被人吐槽，因为它比较鸡肋，相关调查数据也反映了这一点。此次变化，特别是对于普遍不习惯首选 Amazon 购物的中国人来说，是一大好事。</p><p>   Ubuntu 20.04 将使用 Linux 5.4 内核，该版本具有内核锁定模式和 exFAT 支持等新特性。内核锁定功能主要是为了防止 root 帐户篡改内核代码，从而在用户态进程和代码之间划清界限。启用该功能后，即便是 root 帐户也无法访问某些内核功能，从而保护操作系统免受受损的 root 帐户影响。</p></blockquote></blockquote><p>附上原界面图  </p><p><img src="/" class="lazyload" data-src="https://ask.qcloudimg.com/http-save/yehe-1457246/uocrjwsyoh.jpeg?imageView2/2/w/1620"  alt=""></p><p>但是他的界面并不是很好看，所以开始一番整改，然后就是是从网上各种找教程，在这里记录一下我的美化过程。<br>先来一张美化后的效果图吧</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/ghblog-git/img/images/3.png"  alt=""></p><p>下面开始吧</p><h2 id="一，换源"><a href="#一，换源" class="headerlink" title="一，换源"></a>一，换源</h2><p>这第一步当然是换源了。<br>这里演示一下命令行操作  </p><h3 id="1-首先备份原文件"><a href="#1-首先备份原文件" class="headerlink" title="1. 首先备份原文件"></a>1. 首先备份原文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak</span><br></pre></td></tr></table></figure><h3 id="2-替换原文件，使用vim打开，ubuntu20-04需要手动安装一下vim"><a href="#2-替换原文件，使用vim打开，ubuntu20-04需要手动安装一下vim" class="headerlink" title="2. 替换原文件，使用vim打开，ubuntu20.04需要手动安装一下vim"></a>2. 替换原文件，使用vim打开，ubuntu20.04需要手动安装一下vim</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install vim</span><br><span class="line">vim /etc/apt/sources.list</span><br></pre></td></tr></table></figure><p>这是清华的源<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal main restricted</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-updates main restricted</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal universe</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-updates universe</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal multiverse</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-updates multiverse</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-backports main restricted universe multiverse</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-security main restricted</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-security universe</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-security multiverse</span><br></pre></td></tr></table></figure></p><h3 id="3-更新软件列表"><a href="#3-更新软件列表" class="headerlink" title="3. 更新软件列表"></a>3. 更新软件列表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt upgrade</span><br></pre></td></tr></table></figure><h2 id="二，安装神器-gnome-tweak-tool"><a href="#二，安装神器-gnome-tweak-tool" class="headerlink" title="二，安装神器 gnome-tweak-tool"></a>二，安装神器 gnome-tweak-tool</h2><p>开启终端,输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install gnome-tweak-tool</span><br></pre></td></tr></table></figure><br>安装完成后，直接终端输入下面命令就可以启动了<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gnome-tweaks</span><br></pre></td></tr></table></figure></p><p>然后我们需要安装一些扩展插件，在终端中输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install gnome-shell-extensions</span><br></pre></td></tr></table></figure></p><p>安装完后重启一下系统, 然后再打开  优化程序 —&gt; 扩展 </p><p><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223153718808-1636318128.png"  alt=""></p><p>然后关闭程序,重新打开<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223153823199-647024466.png"  alt=""></p><p>那个三角就消失了,然后就可以开始美化了</p><h2 id="三，更改主题"><a href="#三，更改主题" class="headerlink" title="三，更改主题"></a>三，更改主题</h2><p>下面是我挑选的一款主题<br><a href="https://www.gnome-look.org/p/1275087/">主题链接</a></p><p><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223154847596-946695022.png"  alt=""><br>下载完成后解压(Ubuntu叫做提取),右键点击提取到此处就可以<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223155357243-1273308996.png"  alt=""></p><p>然后将主题放入系统主题目录<br>/usr/share/themes/  由于权限问题我们无法直接拖拽到这个目录,所以请使用终端操作复制过去</p><p>在解压的主题所在目录  右键 &gt; 在终端打开<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223155950321-1687064998.png"  alt=""><br>然后输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo cp -r Mojave-light/ /usr/share/themes/</span><br><span class="line"></span><br><span class="line">sudo cp -r Mojave-dark/ /usr/share/themes/</span><br></pre></td></tr></table></figure></p><p>这样就把两个解压好的主题复制主题目录了<br>然后打开 优化程序 &gt; 外观 &gt; 主题 &gt; 应用程序  中就可以选择刚才的两个主题了<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223162026150-112287583.png"  alt=""><br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223162115355-1928043225.png"  alt=""><br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223162138238-38852640.png"  alt=""><br>但是现在顶部标题栏还没有搞定<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223163343510-1846178025.png"  alt=""><br>我们再打开优化程序 更改shell<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223163456421-1636771912.png"  alt=""><br>现在小苹果图标就出来了<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223163530229-1167160920.png"  alt=""></p><h2 id="四，更改软件图标"><a href="#四，更改软件图标" class="headerlink" title="四，更改软件图标"></a>四，更改软件图标</h2><p>主题改好之后，接下来是图标<br><a href="https://www.opendesktop.org/s/Gnome/p/1102582/" target="_blank" rel="noopener">图标链接</a></p><p>和刚刚主题下载一样, files &gt; 选择需要的下载内容<br>下载后放入/usr/share/icons/目录中（这个下载时间会有点久）</p><p>在对应目录打开终端<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp -r Cupertino-Mojave/ /usr/share/icons/</span><br></pre></td></tr></table></figure></p><p>然后打开 优化 &gt; 图标<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223163645153-1612003196.png"  alt=""><br>现在图标就OK了<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223163738933-1598676567.png"  alt=""></p><h2 id="五，修改任务栏位置"><a href="#五，修改任务栏位置" class="headerlink" title="五，修改任务栏位置"></a>五，修改任务栏位置</h2><p>用火狐浏览器打开<br><a href="https://extensions.gnome.org/" target="_blank" rel="noopener">插件商店链接</a><br>（因为一些软件ubuntu的软件商店没有）</p><p>然后允许 &gt; 添加<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223181036324-1947486269.png"  alt=""></p><p> 搜索Dash to Dock ，然后点击安装<br> 安装完后<br><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1427483/201902/1427483-20190223180029867-227535643.png"  alt=""></p><h2 id="六，更换壁纸"><a href="#六，更换壁纸" class="headerlink" title="六，更换壁纸"></a>六，更换壁纸</h2><p>最后更换壁纸就ok啦！<br>到这里就结束啦</p><p>本文参考如下：<br><a href="https://www.cnblogs.com/WXGC-yang/p/10423301.html" target="_blank" rel="noopener">文章链接</a></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SCRAPY框架</title>
      <link href="/posts/5702/"/>
      <url>/posts/5702/</url>
      
        <content type="html"><![CDATA[<h2 id="Scrapy-简介"><a href="#Scrapy-简介" class="headerlink" title="Scrapy 简介"></a>Scrapy 简介</h2><p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架，非常出名，非常强悍。所谓的框架就是一个已经被集成了各种功能（高性能异步下载，队列，分布式，解析，持久化等）的具有很强通用性的项目模板。对于框架的学习，重点是要学习其框架的特性、各个功能的用法即可。</p><h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Windows：</span><br><span class="line">      a. pip3 install wheel</span><br><span class="line">      b. 下载twisted http:&#x2F;&#x2F;www.lfd.uci.edu&#x2F;~gohlke&#x2F;pythonlibs&#x2F;#twisted</span><br><span class="line">      c. 进入下载目录，执行 pip3 install Twisted‑17.1.0‑cp35‑cp35m‑win_amd64.whl</span><br><span class="line">      d. pip3 install pywin32</span><br><span class="line">      e. pip3 install scrapy</span><br></pre></td></tr></table></figure><h2 id="使用介绍"><a href="#使用介绍" class="headerlink" title="使用介绍"></a>使用介绍</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject 项目名称</span><br><span class="line">cd project_name（进入项目目录）</span><br><span class="line">scrapy genspider 应用名称 爬取网页的起始url</span><br><span class="line">scrapy.cfg   项目的主配置信息。（真正爬虫相关的配置信息在settings.py文件中）</span><br><span class="line">items.py     设置数据存储模板，用于结构化数据，如：Django的Model</span><br><span class="line">pipelines    数据持久化处理</span><br><span class="line">settings.py  配置文件，如：递归的层数、并发数，延迟下载等</span><br><span class="line">spiders      爬虫目录，如：创建文件，编写爬虫解析规则</span><br><span class="line"></span><br><span class="line">scrapy crawl  应用名称  运行爬虫</span><br></pre></td></tr></table></figure><p><img src="/" class="lazyload" data-src="https://img2018.cnblogs.com/blog/1364097/201809/1364097-20180928164021096-1215479256.png"  alt="框架流程" title="optional title">  </p><h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    引擎首先会将爬文件中的起始url获取，并且提交到调度器中。                      </span><br><span class="line">如果需要从url中下载数据，则调度器会将url通过引擎提交给下载器，</span><br><span class="line">下载器根据url去下载指定内容（响应体）。下载好的数据会通过引擎</span><br><span class="line">移交给爬虫文件，爬虫文件可以将下载的数据进行指定格式的解析。如果</span><br><span class="line">解析出的数据需要进行持久化存储，则爬虫文件会将解析好的数据通过引</span><br><span class="line">擎移交给管道进行持久化存储。</span><br></pre></td></tr></table></figure><p><em>文章搬运自迎风而来大佬的博客</em><br><em>搬运过来是为了方便自己 哈哈哈</em><br><em><a href="https://www.cnblogs.com/sui776265233/p/9719463.html#_label1" target="_blank" rel="noopener">https://www.cnblogs.com/sui776265233/p/9719463.html#_label1</a></em></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux基本命令</title>
      <link href="/posts/65062/"/>
      <url>/posts/65062/</url>
      
        <content type="html"><![CDATA[<h2 id="ubuntu："><a href="#ubuntu：" class="headerlink" title="ubuntu："></a>ubuntu：</h2><h3 id="查看历史命令"><a href="#查看历史命令" class="headerlink" title="查看历史命令"></a>查看历史命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history</span><br></pre></td></tr></table></figure><h3 id="目录的相关操作："><a href="#目录的相关操作：" class="headerlink" title="目录的相关操作："></a>目录的相关操作：</h3><h4 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h4><blockquote><p>ls      查看目录<br>ls -a  查看所有的子目录及文件（包括隐藏的）<br>ls -l    详细信息 包括创建信息权限等<br>ls —color  查看文件的颜色</p><blockquote><p>   白色：表示普通文件<br>   蓝色：表示目录<br>   绿色：表示可执行文件（使用./文件名 执行）<br>   红色：表示压缩文件<br>   浅蓝色：链接文件<br>   红色闪烁：表示链接的文件<br>   黄色：表示设备文件<br>   灰色：表示其它文件</p></blockquote><p>tree 查看当前目录树形结构</p><p>pwd   查看当前路径</p></blockquote><h4 id="切换"><a href="#切换" class="headerlink" title="切换"></a>切换</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd 目录名  进入到xxx目录</span><br><span class="line">cd ..   到上级目录</span><br><span class="line">cd ..&#x2F;..        到上两级目录</span><br><span class="line">cd &#x2F;home    到当前用户的home目录</span><br><span class="line">cd ～    到根目录</span><br></pre></td></tr></table></figure><h4 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">创建目录（文件夹）</span><br><span class="line">sudo mkdir 目录名字 创建目录</span><br><span class="line">sudo mkdir -p  父目录名&#x2F;子目录名&#x2F;孙目录名</span><br></pre></td></tr></table></figure><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo rmdir 目录名</span><br><span class="line">sudo rmdir -p #递归删除  目录里边不能再有子目录或者文件 </span><br><span class="line"></span><br><span class="line">万能删除</span><br><span class="line">rm -rf 文件名 or 目录名（什么都能删）</span><br><span class="line">    参数r :表示递归删除</span><br><span class="line">    参数f :表示强制删除</span><br><span class="line">    参数i :交互式删除 删除前需要用户进行确认</span><br><span class="line">切记：rm -rf &#x2F;*  删库跑路 慎用！！！</span><br></pre></td></tr></table></figure><h3 id="如何设置软链接"><a href="#如何设置软链接" class="headerlink" title="如何设置软链接"></a>如何设置软链接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">link </span><br><span class="line">ln -s 源文件的名字 新名字(快捷方式的名字)</span><br></pre></td></tr></table></figure><h3 id="文件复制-目录复制"><a href="#文件复制-目录复制" class="headerlink" title="文件复制 目录复制"></a>文件复制 目录复制</h3><p>cp [参数] 原文件或目录 目标文件或目录<br>or [参数] 源文件或目录  目标文件或目录  </p><pre><code>- a 该选项通常在拷贝目录时使用。它保留链接、文件属性，并递归地拷贝目录- d 拷贝时保留链接- f 删除已经存在的目标文件而不提示- i 和f选项相反，在覆盖目标文件之前将给出提示要求用户确认。回答y时目标文件将被覆盖，是交互式拷贝- p 此时cp除复制源文件的内容外，还将把其修改时间和访问权限也复制到新文件中- r 若给出的源文件是一目录文件，此时cp将递归复制该目录下所有的子目录和文件。此时目标文件必须为一个目录名。- l 不作拷贝，只是链接文件</code></pre><h3 id="增加文件或者目录的权限"><a href="#增加文件或者目录的权限" class="headerlink" title="增加文件或者目录的权限"></a>增加文件或者目录的权限</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chomd 777 文件名 代表赋予所有的权限</span><br><span class="line">chomd +w (增加w的权限)   其他的类推</span><br><span class="line">            -w（减去w的权限）</span><br></pre></td></tr></table></figure><h3 id="vim-编辑器"><a href="#vim-编辑器" class="headerlink" title="vim 编辑器"></a>vim 编辑器</h3><p>vi和vim操作基本一样<br>vim熟练了是一个非常棒的编辑器<br>如果没有vim请使用命令安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install vim</span><br></pre></td></tr></table></figure></p><p>基本命令：</p><p>a 进入编辑模式  </p><p>在编辑模式下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">i 在光标所在的位置插入元素</span><br><span class="line">o 在光标的下一行输入</span><br><span class="line">a 在光标下一行输入</span><br><span class="line">I 在光标所在行的行首进行输入</span><br><span class="line">A 在光标所在行的行尾进行输入</span><br></pre></td></tr></table></figure><br>Esc 回到命令模式</p><p>在命令模式下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">h 向左移动一个字符</span><br><span class="line">l 向右移动一个字符</span><br><span class="line">j 向下移动一个字符</span><br><span class="line">k 向上移动一个字符</span><br><span class="line">yy 复制</span><br><span class="line">nyy 复制n行 eg：100yy  复制100行</span><br><span class="line">p 粘贴</span><br><span class="line">np 复制n行   eg：10p 复制10行</span><br><span class="line">dd 删除1行</span><br><span class="line">ndd 删除n行  eg：100dd 删除100行</span><br><span class="line">u 撤销  （相当于windows中的ctrl+z）</span><br></pre></td></tr></table></figure></p><p>: 进入底部命令模式</p><p>底部命令模式下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">:w 保存不退出</span><br><span class="line">:q 不保存退出</span><br><span class="line">:wq 保存并退出</span><br><span class="line">:wq! 强制保存并退出（！表示强制）</span><br><span class="line">:x 保存并退出  &#x3D;&#x3D; wq</span><br><span class="line">:set nu 显示行号</span><br><span class="line">:行号  定位到当前行</span><br><span class="line">&#x2F;要查找的内容   查找到多个 n 跳转到下一个</span><br><span class="line">:s&#x2F;要查找的字符串&#x2F;要替换的字符串</span><br></pre></td></tr></table></figure></p><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>tar 打包  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zcvf 文件名 文件1 文件2 文件3</span><br><span class="line">tar -zxvf 包名       解压tar 包</span><br></pre></td></tr></table></figure><p>解压zip文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip -zxvf zip文件名</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 嵌入式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>异步爬虫 asyncio</title>
      <link href="/posts/56582/"/>
      <url>/posts/56582/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">以前学了爬虫的requests库，感觉功能很强大，爬取速度很快，但是随着后续的学习又学到了 多线程threading模块的使用，还有多进程的使用，这些buff加深，让我们的爬虫速度起飞。</span><br><span class="line">但是当我们遇到一些特殊的网站，比如网站在内部实现返回响应的逻辑的时候特意加了5秒的延迟，这个时候多进程效果就不是特别好了。</span><br><span class="line"></span><br><span class="line">对于这种IO密集型任务使用异步爬虫，可使爬取效率显著提高。</span><br></pre></td></tr></table></figure><h2 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">阻塞状态指程序未得到所需计算资源时被挂起的状态。程序在等待某个操作完成期间，自身无法继续处理其他的事情，则称该程序在该操作上是阻塞的。</span><br><span class="line"></span><br><span class="line">常见的阻塞形式有： 网络 I&#x2F;O 阻塞、磁盘 I&#x2F;O 阻塞、用户输入阻塞等。阻塞是无处不在的，</span><br><span class="line">包括CPU切换上下文时，所有的进程都无法真正处理事情，它们也会被阻塞。如果是多核 CPU 则正在执行上下文切换操作的核不可被利用。</span><br></pre></td></tr></table></figure><h2 id="非阻塞"><a href="#非阻塞" class="headerlink" title="非阻塞"></a>非阻塞</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">程序在等待某操作过程中，自身不被阻塞，可以继续处理其他的事情，则称该程序在该操作上是非阻塞的。</span><br><span class="line"></span><br><span class="line">非阻塞并不是在任何程序级别、任何情况下都可以存在的。仅当程序封装的级别可以囊括独立的子程序单元时，它才可能存在非阻塞状态。</span><br><span class="line"></span><br><span class="line">非阻塞的存在是因为阻塞存在，正因为某个操作阻塞导致的耗时与效率低下，我们才要把它变成非阻塞的。</span><br></pre></td></tr></table></figure><h2 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h2><pre><code>不同程序单元为了完成某个任务，在执行过程中需靠某种通信方式以协调一致，我们称这些程序单元是同步执行的。例如购物系统中更新商品库存，需要用“行锁”作为通信信号，让不同的更新请求强制排队顺序执行，那更新库存的操作是同步的。简言之，同步意味着有序。</code></pre><h2 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">为完成某个任务，不同程序单元之间过程中无需通信协调，也能完成任务的方式，不相关的程序单元之间可以是异步的。</span><br><span class="line"></span><br><span class="line">例如，爬虫下载网页。调度程序调用下载程序后，即可调度其他任务，而无需与该下载任务保持通信以协调行为。不同网页的下载、保存等操作都是无关的，也无需相互通知协调。这些异步操作的完成时刻并不确定。</span><br><span class="line"></span><br><span class="line">简言之，异步意味着无序。</span><br></pre></td></tr></table></figure><h2 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">多进程就是利用 CPU 的多核优势，在同一时间并行地执行多个任务，可以大大提高执行效率。</span><br></pre></td></tr></table></figure><h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">协程，英文叫作 Coroutine，又称微线程、纤程，协程是一种用户态的轻量级线程。</span><br><span class="line"></span><br><span class="line">协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。</span><br><span class="line"></span><br><span class="line">协程本质上是个单进程，协程相对于多进程来说，无需线程上下文切换的开销，无需原子操作锁定及同步的开销，编程模型也非常简单。</span><br><span class="line"></span><br><span class="line">我们可以使用协程来实现异步操作，比如在网络爬虫场景下，我们发出一个请求之后，需要等待一定的时间才能得到响应，但其实在这个等待过程中，程序可以干许多其他的事情，等到响应得到之后才切换回来继续处理，这样可以充分利用 CPU 和其他资源，这就是协程的优势。</span><br></pre></td></tr></table></figure><h2 id="协程的几个方法"><a href="#协程的几个方法" class="headerlink" title="协程的几个方法"></a>协程的几个方法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">event_loop：事件循环，相当于一个无限循环，我们可以把一些函数注册到这个事件循环上，当满足条件发生的时候，就会调用对应的处理方法。</span><br><span class="line"></span><br><span class="line">coroutine：中文翻译叫协程，在 Python 中常指代为协程对象类型，我们可以将协程对象注册到时间循环中，它会被事件循环调用。我们可以使用 async 关键字来定义一个方法，这个方法在调用时不会立即被执行，而是返回一个协程对象。</span><br><span class="line"></span><br><span class="line">task：任务，它是对协程对象的进一步封装，包含了任务的各个状态。</span><br><span class="line">future：代表将来执行或没有执行的任务的结果，实际上和 task 没有本质区别。</span><br></pre></td></tr></table></figure><h2 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">execute</span><span class="params">(x)</span>:</span></span><br><span class="line">   print(<span class="string">'Number:'</span>, x)</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">'Coroutine:'</span>, coroutine)</span><br><span class="line">print(<span class="string">'After calling execute'</span>)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(coroutine)</span><br><span class="line">print(<span class="string">'After calling loop'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">运行结果：</span><br><span class="line">Coroutine: &lt;coroutine object execute at <span class="number">0x1034cf830</span>&gt;</span><br><span class="line">After calling execute</span><br><span class="line">Number: <span class="number">1</span></span><br><span class="line">After calling loop</span><br></pre></td></tr></table></figure><p>今天先写到这里,本篇文章是对python异步爬虫库asyncio的概念介绍，和一段简单代码的了解。并没有涉及到异步爬虫实战代码的内容。<br>当然要实现异步爬虫单单使用asynico是不行的，我们还需要异步请求库aiohttp</p><p><em>文章内容参考自崔庆才大佬的 <a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=46#/content" target="_blank" rel="noopener" >52讲轻松搞定网络爬虫</a> 课程</em></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
